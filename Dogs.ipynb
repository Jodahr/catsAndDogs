{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import useful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import History, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# callbacks\n",
    "history = History()\n",
    "tb = TensorBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('/mnt/DataDisk/jodahr/data/Dogs/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      "id       10222 non-null object\n",
      "breed    10222 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n"
     ]
    }
   ],
   "source": [
    "labels_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, subprocess\n",
    "from shutil import copyfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make subdirs for dog breeds\n",
    "for breed in breeds:\n",
    "    os.makedirs('/mnt/DataDisk/jodahr/data/Dogs/training/' + breed, exist_ok=True)\n",
    "    os.makedirs('/mnt/DataDisk/jodahr/data/Dogs/validation/' + breed, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image path\n",
    "path = '/mnt/DataDisk/jodahr/data/Dogs/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(labels_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    filename = row['id'] + '.jpg'\n",
    "    src = path + filename\n",
    "    target = '/mnt/DataDisk/jodahr/data/Dogs/training/' + row['breed']\n",
    "    shutil.copy(src=src, dst=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "    filename = row['id'] + '.jpg'\n",
    "    src = path + filename\n",
    "    target = '/mnt/DataDisk/jodahr/data/Dogs/validation/' + row['breed']\n",
    "    shutil.copy(src=src, dst=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 250, 250\n",
    "\n",
    "train_data_dir = '/mnt/DataDisk/jodahr/data/Dogs/training/'\n",
    "validation_data_dir = '/mnt/DataDisk/jodahr/data/Dogs/validation/'\n",
    "nb_train_samples = 7155\n",
    "nb_validation_samples = 3067\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model topology\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(120))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7155 images belonging to 120 classes.\n",
      "Found 3067 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 248, 248, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 248, 248, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 124, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 122, 122, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 122, 122, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 59, 59, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                3444800   \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 120)               7800      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 120)               0         \n",
      "=================================================================\n",
      "Total params: 3,528,248\n",
      "Trainable params: 3,528,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "223/223 [==============================] - 87s 391ms/step - loss: 4.7752 - acc: 0.0121 - val_loss: 4.7776 - val_acc: 0.0145\n",
      "Epoch 2/150\n",
      "223/223 [==============================] - 87s 390ms/step - loss: 4.7480 - acc: 0.0185 - val_loss: 4.7033 - val_acc: 0.0204\n",
      "Epoch 3/150\n",
      "223/223 [==============================] - 87s 388ms/step - loss: 4.6822 - acc: 0.0198 - val_loss: 4.6393 - val_acc: 0.0234\n",
      "Epoch 4/150\n",
      "223/223 [==============================] - 87s 390ms/step - loss: 4.6348 - acc: 0.0241 - val_loss: 4.5664 - val_acc: 0.0283\n",
      "Epoch 5/150\n",
      "223/223 [==============================] - 86s 387ms/step - loss: 4.5756 - acc: 0.0304 - val_loss: 4.5290 - val_acc: 0.0339\n",
      "Epoch 6/150\n",
      "223/223 [==============================] - 86s 387ms/step - loss: 4.5443 - acc: 0.0300 - val_loss: 4.5034 - val_acc: 0.0359\n",
      "Epoch 7/150\n",
      "223/223 [==============================] - 86s 387ms/step - loss: 4.5066 - acc: 0.0370 - val_loss: 4.4854 - val_acc: 0.0349\n",
      "Epoch 8/150\n",
      "223/223 [==============================] - 86s 387ms/step - loss: 4.4778 - acc: 0.0348 - val_loss: 4.4426 - val_acc: 0.0388\n",
      "Epoch 9/150\n",
      "223/223 [==============================] - 86s 386ms/step - loss: 4.4373 - acc: 0.0356 - val_loss: 4.4126 - val_acc: 0.0487\n",
      "Epoch 10/150\n",
      "223/223 [==============================] - 86s 384ms/step - loss: 4.3805 - acc: 0.0491 - val_loss: 4.3776 - val_acc: 0.0513\n",
      "Epoch 11/150\n",
      "223/223 [==============================] - 85s 383ms/step - loss: 4.3476 - acc: 0.0511 - val_loss: 4.3607 - val_acc: 0.0516\n",
      "Epoch 12/150\n",
      "223/223 [==============================] - 85s 381ms/step - loss: 4.3152 - acc: 0.0517 - val_loss: 4.3461 - val_acc: 0.0530\n",
      "Epoch 13/150\n",
      "223/223 [==============================] - 85s 381ms/step - loss: 4.2739 - acc: 0.0627 - val_loss: 4.3180 - val_acc: 0.0526\n",
      "Epoch 14/150\n",
      "223/223 [==============================] - 85s 380ms/step - loss: 4.2375 - acc: 0.0597 - val_loss: 4.2674 - val_acc: 0.0569\n",
      "Epoch 15/150\n",
      "223/223 [==============================] - 85s 380ms/step - loss: 4.2076 - acc: 0.0664 - val_loss: 4.2894 - val_acc: 0.0576\n",
      "Epoch 16/150\n",
      "223/223 [==============================] - 85s 380ms/step - loss: 4.1812 - acc: 0.0665 - val_loss: 4.2616 - val_acc: 0.0599\n",
      "Epoch 17/150\n",
      "223/223 [==============================] - 85s 379ms/step - loss: 4.1458 - acc: 0.0750 - val_loss: 4.2417 - val_acc: 0.0664\n",
      "Epoch 18/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 4.1145 - acc: 0.0796 - val_loss: 4.2428 - val_acc: 0.0658\n",
      "Epoch 19/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 4.0848 - acc: 0.0867 - val_loss: 4.2573 - val_acc: 0.0602\n",
      "Epoch 20/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 4.0630 - acc: 0.0897 - val_loss: 4.2415 - val_acc: 0.0697\n",
      "Epoch 21/150\n",
      "223/223 [==============================] - 84s 379ms/step - loss: 4.0320 - acc: 0.0887 - val_loss: 4.2153 - val_acc: 0.0717\n",
      "Epoch 22/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.9872 - acc: 0.0895 - val_loss: 4.2020 - val_acc: 0.0707\n",
      "Epoch 23/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.9736 - acc: 0.0994 - val_loss: 4.2070 - val_acc: 0.0720\n",
      "Epoch 24/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.9480 - acc: 0.0975 - val_loss: 4.1952 - val_acc: 0.0757\n",
      "Epoch 25/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.9052 - acc: 0.1057 - val_loss: 4.1833 - val_acc: 0.0734\n",
      "Epoch 26/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.8837 - acc: 0.1064 - val_loss: 4.1932 - val_acc: 0.0747\n",
      "Epoch 27/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.8553 - acc: 0.1121 - val_loss: 4.2121 - val_acc: 0.0763\n",
      "Epoch 28/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.8084 - acc: 0.1182 - val_loss: 4.1751 - val_acc: 0.0789\n",
      "Epoch 29/150\n",
      "223/223 [==============================] - 84s 379ms/step - loss: 3.8005 - acc: 0.1165 - val_loss: 4.1963 - val_acc: 0.0786\n",
      "Epoch 30/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.7646 - acc: 0.1241 - val_loss: 4.1647 - val_acc: 0.0793\n",
      "Epoch 31/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 3.7437 - acc: 0.1340 - val_loss: 4.1648 - val_acc: 0.0816\n",
      "Epoch 32/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.7390 - acc: 0.1274 - val_loss: 4.2212 - val_acc: 0.0793\n",
      "Epoch 33/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.7127 - acc: 0.1295 - val_loss: 4.1778 - val_acc: 0.0760\n",
      "Epoch 34/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.6854 - acc: 0.1344 - val_loss: 4.2015 - val_acc: 0.0770\n",
      "Epoch 35/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.6465 - acc: 0.1436 - val_loss: 4.1952 - val_acc: 0.0819\n",
      "Epoch 36/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.6378 - acc: 0.1430 - val_loss: 4.2191 - val_acc: 0.0757\n",
      "Epoch 37/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.5907 - acc: 0.1470 - val_loss: 4.2048 - val_acc: 0.0786\n",
      "Epoch 38/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.6158 - acc: 0.1382 - val_loss: 4.1695 - val_acc: 0.0878\n",
      "Epoch 39/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.5777 - acc: 0.1498 - val_loss: 4.2276 - val_acc: 0.0842\n",
      "Epoch 40/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 3.5705 - acc: 0.1494 - val_loss: 4.1992 - val_acc: 0.0865\n",
      "Epoch 41/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.5685 - acc: 0.1528 - val_loss: 4.2417 - val_acc: 0.0819\n",
      "Epoch 42/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.5279 - acc: 0.1605 - val_loss: 4.2426 - val_acc: 0.0852\n",
      "Epoch 43/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.5028 - acc: 0.1611 - val_loss: 4.2066 - val_acc: 0.0865\n",
      "Epoch 44/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 3.4960 - acc: 0.1631 - val_loss: 4.2471 - val_acc: 0.0855\n",
      "Epoch 45/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.4709 - acc: 0.1679 - val_loss: 4.1949 - val_acc: 0.0862\n",
      "Epoch 46/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 3.4357 - acc: 0.1721 - val_loss: 4.3284 - val_acc: 0.0816\n",
      "Epoch 47/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.4432 - acc: 0.1737 - val_loss: 4.2859 - val_acc: 0.0908\n",
      "Epoch 48/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.4209 - acc: 0.1732 - val_loss: 4.2276 - val_acc: 0.0852\n",
      "Epoch 49/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 3.4007 - acc: 0.1759 - val_loss: 4.2680 - val_acc: 0.0918\n",
      "Epoch 50/150\n",
      "223/223 [==============================] - 84s 379ms/step - loss: 3.4013 - acc: 0.1778 - val_loss: 4.2821 - val_acc: 0.0882\n",
      "Epoch 51/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.3395 - acc: 0.1913 - val_loss: 4.2788 - val_acc: 0.0895\n",
      "Epoch 52/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.3392 - acc: 0.1890 - val_loss: 4.2888 - val_acc: 0.0964\n",
      "Epoch 53/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.3447 - acc: 0.1845 - val_loss: 4.2676 - val_acc: 0.0878\n",
      "Epoch 54/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 3.3233 - acc: 0.1845 - val_loss: 4.3067 - val_acc: 0.0878\n",
      "Epoch 55/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.3186 - acc: 0.1812 - val_loss: 4.3083 - val_acc: 0.0895\n",
      "Epoch 56/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.2413 - acc: 0.2008 - val_loss: 4.3148 - val_acc: 0.0911\n",
      "Epoch 57/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.2906 - acc: 0.1991 - val_loss: 4.3411 - val_acc: 0.0878\n",
      "Epoch 58/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.2806 - acc: 0.1997 - val_loss: 4.3536 - val_acc: 0.0914\n",
      "Epoch 59/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.2335 - acc: 0.2012 - val_loss: 4.3446 - val_acc: 0.0882\n",
      "Epoch 60/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 3.2342 - acc: 0.2047 - val_loss: 4.3254 - val_acc: 0.0944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.2233 - acc: 0.2146 - val_loss: 4.3385 - val_acc: 0.0908\n",
      "Epoch 62/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.1757 - acc: 0.2075 - val_loss: 4.3753 - val_acc: 0.0941\n",
      "Epoch 63/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.2067 - acc: 0.2076 - val_loss: 4.3188 - val_acc: 0.0921\n",
      "Epoch 64/150\n",
      "223/223 [==============================] - 85s 380ms/step - loss: 3.1696 - acc: 0.2098 - val_loss: 4.3478 - val_acc: 0.0888\n",
      "Epoch 65/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.1615 - acc: 0.2205 - val_loss: 4.4468 - val_acc: 0.0941\n",
      "Epoch 66/150\n",
      "223/223 [==============================] - 83s 374ms/step - loss: 3.1317 - acc: 0.2204 - val_loss: 4.3637 - val_acc: 0.0859\n",
      "Epoch 67/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.1127 - acc: 0.2224 - val_loss: 4.4020 - val_acc: 0.0895\n",
      "Epoch 68/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.1311 - acc: 0.2247 - val_loss: 4.3844 - val_acc: 0.0938\n",
      "Epoch 69/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.1064 - acc: 0.2240 - val_loss: 4.4371 - val_acc: 0.0895\n",
      "Epoch 70/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 3.1017 - acc: 0.2276 - val_loss: 4.4773 - val_acc: 0.0918\n",
      "Epoch 71/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.1204 - acc: 0.2179 - val_loss: 4.4156 - val_acc: 0.0934\n",
      "Epoch 72/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 3.0890 - acc: 0.2290 - val_loss: 4.4792 - val_acc: 0.0888\n",
      "Epoch 73/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.0554 - acc: 0.2345 - val_loss: 4.4390 - val_acc: 0.0921\n",
      "Epoch 74/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 3.0199 - acc: 0.2331 - val_loss: 4.4796 - val_acc: 0.0895\n",
      "Epoch 75/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.0209 - acc: 0.2443 - val_loss: 4.4382 - val_acc: 0.0868\n",
      "Epoch 76/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.0525 - acc: 0.2344 - val_loss: 4.4606 - val_acc: 0.0888\n",
      "Epoch 77/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 3.0190 - acc: 0.2361 - val_loss: 4.5603 - val_acc: 0.0862\n",
      "Epoch 78/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.9892 - acc: 0.2486 - val_loss: 4.5720 - val_acc: 0.0984\n",
      "Epoch 79/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 3.0186 - acc: 0.2393 - val_loss: 4.4417 - val_acc: 0.0961\n",
      "Epoch 80/150\n",
      "223/223 [==============================] - 85s 380ms/step - loss: 2.9755 - acc: 0.2549 - val_loss: 4.5177 - val_acc: 0.0918\n",
      "Epoch 81/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.9798 - acc: 0.2462 - val_loss: 4.5442 - val_acc: 0.0901\n",
      "Epoch 82/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.9633 - acc: 0.2502 - val_loss: 4.4917 - val_acc: 0.0924\n",
      "Epoch 83/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.9574 - acc: 0.2584 - val_loss: 4.4821 - val_acc: 0.0905\n",
      "Epoch 84/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 2.9494 - acc: 0.2502 - val_loss: 4.4957 - val_acc: 0.0944\n",
      "Epoch 85/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.9561 - acc: 0.2556 - val_loss: 4.5259 - val_acc: 0.0974\n",
      "Epoch 86/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.9342 - acc: 0.2573 - val_loss: 4.5617 - val_acc: 0.0931\n",
      "Epoch 87/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.9154 - acc: 0.2555 - val_loss: 4.5884 - val_acc: 0.0931\n",
      "Epoch 88/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.9118 - acc: 0.2573 - val_loss: 4.6435 - val_acc: 0.0974\n",
      "Epoch 89/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.8848 - acc: 0.2633 - val_loss: 4.6591 - val_acc: 0.0862\n",
      "Epoch 90/150\n",
      "223/223 [==============================] - 83s 374ms/step - loss: 2.8729 - acc: 0.2693 - val_loss: 4.5457 - val_acc: 0.0898\n",
      "Epoch 91/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.8832 - acc: 0.2674 - val_loss: 4.6755 - val_acc: 0.0918\n",
      "Epoch 92/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.8587 - acc: 0.2693 - val_loss: 4.6028 - val_acc: 0.0905\n",
      "Epoch 93/150\n",
      "223/223 [==============================] - 84s 374ms/step - loss: 2.8899 - acc: 0.2630 - val_loss: 4.6099 - val_acc: 0.0980\n",
      "Epoch 94/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.8486 - acc: 0.2734 - val_loss: 4.6961 - val_acc: 0.0990\n",
      "Epoch 95/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.8326 - acc: 0.2724 - val_loss: 4.6836 - val_acc: 0.0941\n",
      "Epoch 96/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.8057 - acc: 0.2693 - val_loss: 4.6487 - val_acc: 0.0901\n",
      "Epoch 97/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 2.8492 - acc: 0.2727 - val_loss: 4.6649 - val_acc: 0.0974\n",
      "Epoch 98/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 2.7706 - acc: 0.2802 - val_loss: 4.7210 - val_acc: 0.0980\n",
      "Epoch 99/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.8481 - acc: 0.2704 - val_loss: 4.6643 - val_acc: 0.0918\n",
      "Epoch 100/150\n",
      "223/223 [==============================] - 85s 380ms/step - loss: 2.7897 - acc: 0.2787 - val_loss: 4.6757 - val_acc: 0.0941\n",
      "Epoch 101/150\n",
      "223/223 [==============================] - 83s 374ms/step - loss: 2.7938 - acc: 0.2845 - val_loss: 4.6450 - val_acc: 0.0914\n",
      "Epoch 102/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.7933 - acc: 0.2814 - val_loss: 4.6746 - val_acc: 0.0908\n",
      "Epoch 103/150\n",
      "223/223 [==============================] - 83s 374ms/step - loss: 2.7735 - acc: 0.2875 - val_loss: 4.6697 - val_acc: 0.0951\n",
      "Epoch 104/150\n",
      "223/223 [==============================] - 83s 373ms/step - loss: 2.7400 - acc: 0.2941 - val_loss: 4.6529 - val_acc: 0.0934\n",
      "Epoch 105/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.7330 - acc: 0.2953 - val_loss: 4.8019 - val_acc: 0.0898\n",
      "Epoch 106/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.7547 - acc: 0.2886 - val_loss: 4.6435 - val_acc: 0.0901\n",
      "Epoch 107/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.7579 - acc: 0.2887 - val_loss: 4.7068 - val_acc: 0.0993\n",
      "Epoch 108/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.6733 - acc: 0.3052 - val_loss: 4.7882 - val_acc: 0.0924\n",
      "Epoch 109/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.7605 - acc: 0.2875 - val_loss: 4.7345 - val_acc: 0.0921\n",
      "Epoch 110/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.7272 - acc: 0.2916 - val_loss: 4.7977 - val_acc: 0.0931\n",
      "Epoch 111/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.6959 - acc: 0.2955 - val_loss: 4.7940 - val_acc: 0.0931\n",
      "Epoch 112/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.7167 - acc: 0.2909 - val_loss: 4.7816 - val_acc: 0.0954\n",
      "Epoch 113/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.6988 - acc: 0.3012 - val_loss: 4.8459 - val_acc: 0.0951\n",
      "Epoch 114/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.7013 - acc: 0.3056 - val_loss: 4.8727 - val_acc: 0.0895\n",
      "Epoch 115/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.7024 - acc: 0.2928 - val_loss: 4.7549 - val_acc: 0.0914\n",
      "Epoch 116/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 2.6612 - acc: 0.3159 - val_loss: 4.8403 - val_acc: 0.0911\n",
      "Epoch 117/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.6774 - acc: 0.3014 - val_loss: 4.7900 - val_acc: 0.0931\n",
      "Epoch 118/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.6112 - acc: 0.3219 - val_loss: 4.9932 - val_acc: 0.0938\n",
      "Epoch 119/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.6282 - acc: 0.3112 - val_loss: 4.8139 - val_acc: 0.0885\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 84s 377ms/step - loss: 2.6636 - acc: 0.3063 - val_loss: 4.8605 - val_acc: 0.0934\n",
      "Epoch 121/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.6592 - acc: 0.3089 - val_loss: 4.8163 - val_acc: 0.0872\n",
      "Epoch 122/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 2.6406 - acc: 0.3088 - val_loss: 4.7712 - val_acc: 0.0931\n",
      "Epoch 123/150\n",
      "223/223 [==============================] - 85s 379ms/step - loss: 2.6529 - acc: 0.3155 - val_loss: 4.7922 - val_acc: 0.0918\n",
      "Epoch 124/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.6413 - acc: 0.3087 - val_loss: 4.8277 - val_acc: 0.0895\n",
      "Epoch 125/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.6232 - acc: 0.3169 - val_loss: 4.8609 - val_acc: 0.0928\n",
      "Epoch 126/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 2.6275 - acc: 0.3177 - val_loss: 4.8539 - val_acc: 0.0947\n",
      "Epoch 127/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.5766 - acc: 0.3274 - val_loss: 4.8761 - val_acc: 0.0898\n",
      "Epoch 128/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.6069 - acc: 0.3234 - val_loss: 5.1146 - val_acc: 0.0859\n",
      "Epoch 129/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.5807 - acc: 0.3177 - val_loss: 4.9640 - val_acc: 0.0931\n",
      "Epoch 130/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.6107 - acc: 0.3174 - val_loss: 4.8632 - val_acc: 0.0928\n",
      "Epoch 131/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.5686 - acc: 0.3241 - val_loss: 5.0145 - val_acc: 0.0911\n",
      "Epoch 132/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.5506 - acc: 0.3292 - val_loss: 4.9761 - val_acc: 0.0852\n",
      "Epoch 133/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.5544 - acc: 0.3255 - val_loss: 4.9328 - val_acc: 0.0878\n",
      "Epoch 134/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.5436 - acc: 0.3338 - val_loss: 4.8793 - val_acc: 0.0826\n",
      "Epoch 135/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.5424 - acc: 0.3316 - val_loss: 5.0724 - val_acc: 0.0924\n",
      "Epoch 136/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.5618 - acc: 0.3288 - val_loss: 4.9311 - val_acc: 0.0918\n",
      "Epoch 137/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.5494 - acc: 0.3268 - val_loss: 4.8960 - val_acc: 0.0872\n",
      "Epoch 138/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.5274 - acc: 0.3334 - val_loss: 4.8913 - val_acc: 0.0901\n",
      "Epoch 139/150\n",
      "223/223 [==============================] - 84s 379ms/step - loss: 2.5413 - acc: 0.3300 - val_loss: 4.9563 - val_acc: 0.0901\n",
      "Epoch 140/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.5591 - acc: 0.3174 - val_loss: 4.9283 - val_acc: 0.0901\n",
      "Epoch 141/150\n",
      "223/223 [==============================] - 83s 373ms/step - loss: 2.5245 - acc: 0.3295 - val_loss: 4.8899 - val_acc: 0.0924\n",
      "Epoch 142/150\n",
      "223/223 [==============================] - 84s 378ms/step - loss: 2.5273 - acc: 0.3316 - val_loss: 4.9882 - val_acc: 0.0898\n",
      "Epoch 143/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.5052 - acc: 0.3381 - val_loss: 5.0217 - val_acc: 0.0911\n",
      "Epoch 144/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.5309 - acc: 0.3257 - val_loss: 4.9900 - val_acc: 0.0888\n",
      "Epoch 145/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.4928 - acc: 0.3381 - val_loss: 5.0457 - val_acc: 0.0931\n",
      "Epoch 146/150\n",
      "223/223 [==============================] - 85s 380ms/step - loss: 2.5261 - acc: 0.3304 - val_loss: 4.8539 - val_acc: 0.0836\n",
      "Epoch 147/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.4861 - acc: 0.3350 - val_loss: 5.0679 - val_acc: 0.0839\n",
      "Epoch 148/150\n",
      "223/223 [==============================] - 84s 377ms/step - loss: 2.4774 - acc: 0.3419 - val_loss: 5.0210 - val_acc: 0.0822\n",
      "Epoch 149/150\n",
      "223/223 [==============================] - 84s 376ms/step - loss: 2.4703 - acc: 0.3455 - val_loss: 5.1875 - val_acc: 0.0878\n",
      "Epoch 150/150\n",
      "223/223 [==============================] - 84s 375ms/step - loss: 2.4949 - acc: 0.3392 - val_loss: 5.0292 - val_acc: 0.0891\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks = [history, tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 9546524367860712878, name: \"/gpu:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9633792\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 1049322012252770017\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:0c:00.0\"]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
