{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import useful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import History, TensorBoard\n",
    "from keras import applications\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# callbacks\n",
    "history = History()\n",
    "tb = TensorBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('/mnt/DataDisk/jodahr/data/Dogs/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      "id       10222 non-null object\n",
      "breed    10222 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n"
     ]
    }
   ],
   "source": [
    "labels_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, subprocess\n",
    "from shutil import copyfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'breeds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1b969059b9b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make subdirs for dog breeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbreed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbreeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/DataDisk/jodahr/data/Dogs/training/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbreed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/DataDisk/jodahr/data/Dogs/validation/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbreed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'breeds' is not defined"
     ]
    }
   ],
   "source": [
    "# make subdirs for dog breeds\n",
    "for breed in breeds:\n",
    "    os.makedirs('/mnt/DataDisk/jodahr/data/Dogs/training/' + breed, exist_ok=True)\n",
    "    os.makedirs('/mnt/DataDisk/jodahr/data/Dogs/validation/' + breed, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image path\n",
    "path = '/mnt/DataDisk/jodahr/data/Dogs/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(labels_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    filename = row['id'] + '.jpg'\n",
    "    src = path + filename\n",
    "    target = '/mnt/DataDisk/jodahr/data/Dogs/training/' + row['breed']\n",
    "    shutil.copy(src=src, dst=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in test.iterrows():\n",
    "    filename = row['id'] + '.jpg'\n",
    "    src = path + filename\n",
    "    target = '/mnt/DataDisk/jodahr/data/Dogs/validation/' + row['breed']\n",
    "    shutil.copy(src=src, dst=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 250, 250\n",
    "\n",
    "train_data_dir = '/mnt/DataDisk/jodahr/data/Dogs/training/'\n",
    "validation_data_dir = '/mnt/DataDisk/jodahr/data/Dogs/validation/'\n",
    "nb_train_samples = 7155\n",
    "nb_validation_samples = 3067\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = applications.VGG16(include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 250, 250, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 250, 250, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 250, 250, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 125, 125, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 125, 125, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 125, 125, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 62, 62, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 31, 31, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 250, 250, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 250, 250, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 250, 250, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 125, 125, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 125, 125, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 125, 125, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 62, 62, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 31, 31, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model topology\n",
    "top_model = Sequential()\n",
    "\n",
    "top_model.add(Conv2D(32, (3, 3), input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Activation('relu'))\n",
    "top_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "top_model.add(Flatten())\n",
    "top_model.add(Dense(32))\n",
    "top_model.add(Activation('relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(120))\n",
    "top_model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras import metrics\n",
    "\n",
    "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7155 images belonging to 120 classes.\n",
      "Found 3067 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 250, 250, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 250, 250, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 250, 250, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 125, 125, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 125, 125, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 125, 125, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 62, 62, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 31, 31, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 120)               155576    \n",
      "=================================================================\n",
      "Total params: 14,870,264\n",
      "Trainable params: 155,576\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "111/111 [==============================] - 108s 971ms/step - loss: 4.7443 - categorical_accuracy: 0.0145 - val_loss: 4.6810 - val_categorical_accuracy: 0.0173\n",
      "Epoch 2/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 4.6323 - categorical_accuracy: 0.0189 - val_loss: 4.5422 - val_categorical_accuracy: 0.0209\n",
      "Epoch 3/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 4.5282 - categorical_accuracy: 0.0214 - val_loss: 4.4599 - val_categorical_accuracy: 0.0303\n",
      "Epoch 4/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 4.4729 - categorical_accuracy: 0.0232 - val_loss: 4.4349 - val_categorical_accuracy: 0.0283\n",
      "Epoch 5/150\n",
      "111/111 [==============================] - 105s 943ms/step - loss: 4.4177 - categorical_accuracy: 0.0228 - val_loss: 4.3812 - val_categorical_accuracy: 0.0336\n",
      "Epoch 6/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 4.3759 - categorical_accuracy: 0.0294 - val_loss: 4.3464 - val_categorical_accuracy: 0.0346\n",
      "Epoch 7/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 4.3140 - categorical_accuracy: 0.0329 - val_loss: 4.2429 - val_categorical_accuracy: 0.0422\n",
      "Epoch 8/150\n",
      "111/111 [==============================] - 105s 943ms/step - loss: 4.2963 - categorical_accuracy: 0.0320 - val_loss: 4.1958 - val_categorical_accuracy: 0.0419\n",
      "Epoch 9/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 4.2416 - categorical_accuracy: 0.0417 - val_loss: 4.1590 - val_categorical_accuracy: 0.0465\n",
      "Epoch 10/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 4.1969 - categorical_accuracy: 0.0397 - val_loss: 4.1335 - val_categorical_accuracy: 0.0499\n",
      "Epoch 11/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 4.1837 - categorical_accuracy: 0.0402 - val_loss: 4.1062 - val_categorical_accuracy: 0.0535\n",
      "Epoch 12/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 4.1602 - categorical_accuracy: 0.0429 - val_loss: 4.0789 - val_categorical_accuracy: 0.0552\n",
      "Epoch 13/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 4.1204 - categorical_accuracy: 0.0478 - val_loss: 4.0431 - val_categorical_accuracy: 0.0592\n",
      "Epoch 14/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 4.0892 - categorical_accuracy: 0.0525 - val_loss: 4.0290 - val_categorical_accuracy: 0.0612\n",
      "Epoch 15/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 4.0709 - categorical_accuracy: 0.0526 - val_loss: 4.0137 - val_categorical_accuracy: 0.0632\n",
      "Epoch 16/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 4.0671 - categorical_accuracy: 0.0538 - val_loss: 4.0015 - val_categorical_accuracy: 0.0608\n",
      "Epoch 17/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 4.0341 - categorical_accuracy: 0.0551 - val_loss: 3.9796 - val_categorical_accuracy: 0.0668\n",
      "Epoch 18/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 4.0079 - categorical_accuracy: 0.0559 - val_loss: 3.9713 - val_categorical_accuracy: 0.0668\n",
      "Epoch 19/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.9903 - categorical_accuracy: 0.0593 - val_loss: 3.9527 - val_categorical_accuracy: 0.0628\n",
      "Epoch 20/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.9871 - categorical_accuracy: 0.0653 - val_loss: 3.9431 - val_categorical_accuracy: 0.0635\n",
      "Epoch 21/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.9874 - categorical_accuracy: 0.0564 - val_loss: 3.9344 - val_categorical_accuracy: 0.0665\n",
      "Epoch 22/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.9796 - categorical_accuracy: 0.0559 - val_loss: 3.9237 - val_categorical_accuracy: 0.0691\n",
      "Epoch 23/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.9655 - categorical_accuracy: 0.0638 - val_loss: 3.9246 - val_categorical_accuracy: 0.0685\n",
      "Epoch 24/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.9677 - categorical_accuracy: 0.0648 - val_loss: 3.9680 - val_categorical_accuracy: 0.0688\n",
      "Epoch 25/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.9517 - categorical_accuracy: 0.0622 - val_loss: 3.9149 - val_categorical_accuracy: 0.0745\n",
      "Epoch 26/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.9484 - categorical_accuracy: 0.0614 - val_loss: 3.9051 - val_categorical_accuracy: 0.0728\n",
      "Epoch 27/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.9249 - categorical_accuracy: 0.0679 - val_loss: 3.9676 - val_categorical_accuracy: 0.0728\n",
      "Epoch 28/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.9388 - categorical_accuracy: 0.0639 - val_loss: 3.9175 - val_categorical_accuracy: 0.0731\n",
      "Epoch 29/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.9207 - categorical_accuracy: 0.0644 - val_loss: 3.8926 - val_categorical_accuracy: 0.0728\n",
      "Epoch 30/150\n",
      "111/111 [==============================] - 105s 941ms/step - loss: 3.9001 - categorical_accuracy: 0.0701 - val_loss: 3.8939 - val_categorical_accuracy: 0.0758\n",
      "Epoch 31/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8992 - categorical_accuracy: 0.0687 - val_loss: 3.8851 - val_categorical_accuracy: 0.0758\n",
      "Epoch 32/150\n",
      "111/111 [==============================] - 104s 939ms/step - loss: 3.8805 - categorical_accuracy: 0.0714 - val_loss: 3.8927 - val_categorical_accuracy: 0.0718\n",
      "Epoch 33/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.9001 - categorical_accuracy: 0.0671 - val_loss: 3.8772 - val_categorical_accuracy: 0.0765\n",
      "Epoch 34/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.8731 - categorical_accuracy: 0.0668 - val_loss: 3.8845 - val_categorical_accuracy: 0.0748\n",
      "Epoch 35/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.8909 - categorical_accuracy: 0.0731 - val_loss: 3.8721 - val_categorical_accuracy: 0.0765\n",
      "Epoch 36/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8716 - categorical_accuracy: 0.0760 - val_loss: 3.8953 - val_categorical_accuracy: 0.0735\n",
      "Epoch 37/150\n",
      "111/111 [==============================] - 105s 943ms/step - loss: 3.8757 - categorical_accuracy: 0.0743 - val_loss: 3.8669 - val_categorical_accuracy: 0.0768\n",
      "Epoch 38/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8708 - categorical_accuracy: 0.0765 - val_loss: 3.8618 - val_categorical_accuracy: 0.0771\n",
      "Epoch 39/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.8570 - categorical_accuracy: 0.0711 - val_loss: 3.8559 - val_categorical_accuracy: 0.0755\n",
      "Epoch 40/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8631 - categorical_accuracy: 0.0764 - val_loss: 3.8689 - val_categorical_accuracy: 0.0838\n",
      "Epoch 41/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8481 - categorical_accuracy: 0.0787 - val_loss: 3.8639 - val_categorical_accuracy: 0.0798\n",
      "Epoch 42/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8610 - categorical_accuracy: 0.0725 - val_loss: 3.8815 - val_categorical_accuracy: 0.0781\n",
      "Epoch 43/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.8585 - categorical_accuracy: 0.0742 - val_loss: 3.8567 - val_categorical_accuracy: 0.0761\n",
      "Epoch 44/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.8453 - categorical_accuracy: 0.0768 - val_loss: 3.8531 - val_categorical_accuracy: 0.0795\n",
      "Epoch 45/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.8499 - categorical_accuracy: 0.0738 - val_loss: 3.8991 - val_categorical_accuracy: 0.0751\n",
      "Epoch 46/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.8411 - categorical_accuracy: 0.0717 - val_loss: 3.8442 - val_categorical_accuracy: 0.0758\n",
      "Epoch 47/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8361 - categorical_accuracy: 0.0812 - val_loss: 3.8498 - val_categorical_accuracy: 0.0785\n",
      "Epoch 48/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.8408 - categorical_accuracy: 0.0775 - val_loss: 3.8545 - val_categorical_accuracy: 0.0758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.8291 - categorical_accuracy: 0.0797 - val_loss: 3.8522 - val_categorical_accuracy: 0.0768\n",
      "Epoch 50/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.8262 - categorical_accuracy: 0.0783 - val_loss: 3.8481 - val_categorical_accuracy: 0.0795\n",
      "Epoch 51/150\n",
      "111/111 [==============================] - 104s 939ms/step - loss: 3.8266 - categorical_accuracy: 0.0765 - val_loss: 3.8737 - val_categorical_accuracy: 0.0695\n",
      "Epoch 52/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8382 - categorical_accuracy: 0.0753 - val_loss: 3.8590 - val_categorical_accuracy: 0.0758\n",
      "Epoch 53/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.8203 - categorical_accuracy: 0.0814 - val_loss: 3.8514 - val_categorical_accuracy: 0.0795\n",
      "Epoch 54/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8095 - categorical_accuracy: 0.0715 - val_loss: 3.8479 - val_categorical_accuracy: 0.0808\n",
      "Epoch 55/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.8192 - categorical_accuracy: 0.0770 - val_loss: 3.8505 - val_categorical_accuracy: 0.0795\n",
      "Epoch 56/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.8249 - categorical_accuracy: 0.0767 - val_loss: 3.8391 - val_categorical_accuracy: 0.0791\n",
      "Epoch 57/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.8154 - categorical_accuracy: 0.0826 - val_loss: 3.8552 - val_categorical_accuracy: 0.0814\n",
      "Epoch 58/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.8153 - categorical_accuracy: 0.0714 - val_loss: 3.8667 - val_categorical_accuracy: 0.0741\n",
      "Epoch 59/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.8230 - categorical_accuracy: 0.0800 - val_loss: 3.8530 - val_categorical_accuracy: 0.0801\n",
      "Epoch 60/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7979 - categorical_accuracy: 0.0799 - val_loss: 3.8471 - val_categorical_accuracy: 0.0761\n",
      "Epoch 61/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.8173 - categorical_accuracy: 0.0738 - val_loss: 3.8681 - val_categorical_accuracy: 0.0798\n",
      "Epoch 62/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8142 - categorical_accuracy: 0.0782 - val_loss: 3.8904 - val_categorical_accuracy: 0.0728\n",
      "Epoch 63/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7995 - categorical_accuracy: 0.0798 - val_loss: 3.8453 - val_categorical_accuracy: 0.0838\n",
      "Epoch 64/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7961 - categorical_accuracy: 0.0885 - val_loss: 3.8934 - val_categorical_accuracy: 0.0751\n",
      "Epoch 65/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.8343 - categorical_accuracy: 0.0767 - val_loss: 3.8635 - val_categorical_accuracy: 0.0831\n",
      "Epoch 66/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8004 - categorical_accuracy: 0.0836 - val_loss: 3.8391 - val_categorical_accuracy: 0.0765\n",
      "Epoch 67/150\n",
      "111/111 [==============================] - 104s 939ms/step - loss: 3.7821 - categorical_accuracy: 0.0859 - val_loss: 3.8269 - val_categorical_accuracy: 0.0861\n",
      "Epoch 68/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.8110 - categorical_accuracy: 0.0796 - val_loss: 3.8456 - val_categorical_accuracy: 0.0778\n",
      "Epoch 69/150\n",
      "111/111 [==============================] - 105s 943ms/step - loss: 3.7820 - categorical_accuracy: 0.0780 - val_loss: 3.8469 - val_categorical_accuracy: 0.0798\n",
      "Epoch 70/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7587 - categorical_accuracy: 0.0795 - val_loss: 3.8654 - val_categorical_accuracy: 0.0801\n",
      "Epoch 71/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7982 - categorical_accuracy: 0.0766 - val_loss: 3.8484 - val_categorical_accuracy: 0.0778\n",
      "Epoch 72/150\n",
      "111/111 [==============================] - 105s 943ms/step - loss: 3.7881 - categorical_accuracy: 0.0816 - val_loss: 3.8392 - val_categorical_accuracy: 0.0801\n",
      "Epoch 73/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7766 - categorical_accuracy: 0.0823 - val_loss: 3.8391 - val_categorical_accuracy: 0.0785\n",
      "Epoch 74/150\n",
      "111/111 [==============================] - 104s 939ms/step - loss: 3.7942 - categorical_accuracy: 0.0786 - val_loss: 3.8474 - val_categorical_accuracy: 0.0814\n",
      "Epoch 75/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7718 - categorical_accuracy: 0.0832 - val_loss: 3.8456 - val_categorical_accuracy: 0.0778\n",
      "Epoch 76/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7699 - categorical_accuracy: 0.0783 - val_loss: 3.8454 - val_categorical_accuracy: 0.0758\n",
      "Epoch 77/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7699 - categorical_accuracy: 0.0803 - val_loss: 3.8352 - val_categorical_accuracy: 0.0751\n",
      "Epoch 78/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7629 - categorical_accuracy: 0.0828 - val_loss: 3.8769 - val_categorical_accuracy: 0.0768\n",
      "Epoch 79/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7789 - categorical_accuracy: 0.0800 - val_loss: 3.8370 - val_categorical_accuracy: 0.0828\n",
      "Epoch 80/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7648 - categorical_accuracy: 0.0815 - val_loss: 3.8263 - val_categorical_accuracy: 0.0781\n",
      "Epoch 81/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7877 - categorical_accuracy: 0.0807 - val_loss: 3.8298 - val_categorical_accuracy: 0.0844\n",
      "Epoch 82/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7542 - categorical_accuracy: 0.0845 - val_loss: 3.8522 - val_categorical_accuracy: 0.0755\n",
      "Epoch 83/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7693 - categorical_accuracy: 0.0768 - val_loss: 3.8294 - val_categorical_accuracy: 0.0808\n",
      "Epoch 84/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7716 - categorical_accuracy: 0.0838 - val_loss: 3.8347 - val_categorical_accuracy: 0.0801\n",
      "Epoch 85/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7583 - categorical_accuracy: 0.0846 - val_loss: 3.8370 - val_categorical_accuracy: 0.0768\n",
      "Epoch 86/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7919 - categorical_accuracy: 0.0852 - val_loss: 3.8556 - val_categorical_accuracy: 0.0738\n",
      "Epoch 87/150\n",
      "111/111 [==============================] - 104s 939ms/step - loss: 3.7654 - categorical_accuracy: 0.0800 - val_loss: 3.8417 - val_categorical_accuracy: 0.0765\n",
      "Epoch 88/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7850 - categorical_accuracy: 0.0823 - val_loss: 3.8982 - val_categorical_accuracy: 0.0755\n",
      "Epoch 89/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7469 - categorical_accuracy: 0.0834 - val_loss: 3.8481 - val_categorical_accuracy: 0.0805\n",
      "Epoch 90/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7797 - categorical_accuracy: 0.0814 - val_loss: 3.8614 - val_categorical_accuracy: 0.0778\n",
      "Epoch 91/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7507 - categorical_accuracy: 0.0852 - val_loss: 3.8253 - val_categorical_accuracy: 0.0824\n",
      "Epoch 92/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7458 - categorical_accuracy: 0.0891 - val_loss: 3.8228 - val_categorical_accuracy: 0.0795\n",
      "Epoch 93/150\n",
      "111/111 [==============================] - 104s 939ms/step - loss: 3.7595 - categorical_accuracy: 0.0837 - val_loss: 3.8289 - val_categorical_accuracy: 0.0791\n",
      "Epoch 94/150\n",
      "111/111 [==============================] - 105s 943ms/step - loss: 3.7470 - categorical_accuracy: 0.0826 - val_loss: 3.8390 - val_categorical_accuracy: 0.0798\n",
      "Epoch 95/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7566 - categorical_accuracy: 0.0824 - val_loss: 3.8403 - val_categorical_accuracy: 0.0805\n",
      "Epoch 96/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7706 - categorical_accuracy: 0.0844 - val_loss: 3.8382 - val_categorical_accuracy: 0.0738\n",
      "Epoch 97/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7636 - categorical_accuracy: 0.0874 - val_loss: 3.8302 - val_categorical_accuracy: 0.0758\n",
      "Epoch 98/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7414 - categorical_accuracy: 0.0866 - val_loss: 3.8275 - val_categorical_accuracy: 0.0798\n",
      "Epoch 99/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7491 - categorical_accuracy: 0.0815 - val_loss: 3.8312 - val_categorical_accuracy: 0.0791\n",
      "Epoch 100/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7576 - categorical_accuracy: 0.0820 - val_loss: 3.8294 - val_categorical_accuracy: 0.0838\n",
      "Epoch 101/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7330 - categorical_accuracy: 0.0858 - val_loss: 3.8440 - val_categorical_accuracy: 0.0808\n",
      "Epoch 102/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7562 - categorical_accuracy: 0.0872 - val_loss: 3.8410 - val_categorical_accuracy: 0.0788\n",
      "Epoch 103/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7489 - categorical_accuracy: 0.0848 - val_loss: 3.8344 - val_categorical_accuracy: 0.0791\n",
      "Epoch 104/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7491 - categorical_accuracy: 0.0854 - val_loss: 3.8261 - val_categorical_accuracy: 0.0785\n",
      "Epoch 105/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7489 - categorical_accuracy: 0.0851 - val_loss: 3.9031 - val_categorical_accuracy: 0.0688\n",
      "Epoch 106/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7407 - categorical_accuracy: 0.0856 - val_loss: 3.8390 - val_categorical_accuracy: 0.0818\n",
      "Epoch 107/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7527 - categorical_accuracy: 0.0876 - val_loss: 3.8462 - val_categorical_accuracy: 0.0828\n",
      "Epoch 108/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7451 - categorical_accuracy: 0.0814 - val_loss: 3.8358 - val_categorical_accuracy: 0.0805\n",
      "Epoch 109/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7548 - categorical_accuracy: 0.0772 - val_loss: 3.8383 - val_categorical_accuracy: 0.0781\n",
      "Epoch 110/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7377 - categorical_accuracy: 0.0790 - val_loss: 3.8514 - val_categorical_accuracy: 0.0811\n",
      "Epoch 111/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7487 - categorical_accuracy: 0.0831 - val_loss: 3.8420 - val_categorical_accuracy: 0.0798\n",
      "Epoch 112/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7418 - categorical_accuracy: 0.0907 - val_loss: 3.8339 - val_categorical_accuracy: 0.0828\n",
      "Epoch 113/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7414 - categorical_accuracy: 0.0876 - val_loss: 3.8840 - val_categorical_accuracy: 0.0735\n",
      "Epoch 114/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7468 - categorical_accuracy: 0.0869 - val_loss: 3.8398 - val_categorical_accuracy: 0.0771\n",
      "Epoch 115/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7485 - categorical_accuracy: 0.0904 - val_loss: 3.8392 - val_categorical_accuracy: 0.0838\n",
      "Epoch 116/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7446 - categorical_accuracy: 0.0850 - val_loss: 3.8340 - val_categorical_accuracy: 0.0781\n",
      "Epoch 117/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7359 - categorical_accuracy: 0.0820 - val_loss: 3.8523 - val_categorical_accuracy: 0.0768\n",
      "Epoch 118/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7508 - categorical_accuracy: 0.0840 - val_loss: 3.8449 - val_categorical_accuracy: 0.0801\n",
      "Epoch 119/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7387 - categorical_accuracy: 0.0852 - val_loss: 3.8687 - val_categorical_accuracy: 0.0728\n",
      "Epoch 120/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7228 - categorical_accuracy: 0.0892 - val_loss: 3.8560 - val_categorical_accuracy: 0.0788\n",
      "Epoch 121/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7381 - categorical_accuracy: 0.0873 - val_loss: 3.8492 - val_categorical_accuracy: 0.0758\n",
      "Epoch 122/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7252 - categorical_accuracy: 0.0896 - val_loss: 3.8428 - val_categorical_accuracy: 0.0791\n",
      "Epoch 123/150\n",
      "111/111 [==============================] - 105s 941ms/step - loss: 3.7230 - categorical_accuracy: 0.0872 - val_loss: 3.8521 - val_categorical_accuracy: 0.0748\n",
      "Epoch 124/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7262 - categorical_accuracy: 0.0890 - val_loss: 3.8414 - val_categorical_accuracy: 0.0795\n",
      "Epoch 125/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7400 - categorical_accuracy: 0.0899 - val_loss: 3.8373 - val_categorical_accuracy: 0.0785\n",
      "Epoch 126/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7338 - categorical_accuracy: 0.0869 - val_loss: 3.8573 - val_categorical_accuracy: 0.0768\n",
      "Epoch 127/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7271 - categorical_accuracy: 0.0893 - val_loss: 3.8303 - val_categorical_accuracy: 0.0811\n",
      "Epoch 128/150\n",
      "111/111 [==============================] - 105s 943ms/step - loss: 3.7097 - categorical_accuracy: 0.0921 - val_loss: 3.8574 - val_categorical_accuracy: 0.0834\n",
      "Epoch 129/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7180 - categorical_accuracy: 0.0883 - val_loss: 3.8366 - val_categorical_accuracy: 0.0831\n",
      "Epoch 130/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7354 - categorical_accuracy: 0.0843 - val_loss: 3.8608 - val_categorical_accuracy: 0.0878\n",
      "Epoch 131/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7357 - categorical_accuracy: 0.0869 - val_loss: 3.8512 - val_categorical_accuracy: 0.0778\n",
      "Epoch 132/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7441 - categorical_accuracy: 0.0864 - val_loss: 3.8378 - val_categorical_accuracy: 0.0831\n",
      "Epoch 133/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7348 - categorical_accuracy: 0.0873 - val_loss: 3.9109 - val_categorical_accuracy: 0.0831\n",
      "Epoch 134/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7305 - categorical_accuracy: 0.0885 - val_loss: 3.8549 - val_categorical_accuracy: 0.0818\n",
      "Epoch 135/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7236 - categorical_accuracy: 0.0887 - val_loss: 3.8377 - val_categorical_accuracy: 0.0795\n",
      "Epoch 136/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7274 - categorical_accuracy: 0.0908 - val_loss: 3.8447 - val_categorical_accuracy: 0.0795\n",
      "Epoch 137/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7227 - categorical_accuracy: 0.0865 - val_loss: 3.8489 - val_categorical_accuracy: 0.0821\n",
      "Epoch 138/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7211 - categorical_accuracy: 0.0887 - val_loss: 3.8351 - val_categorical_accuracy: 0.0828\n",
      "Epoch 139/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7339 - categorical_accuracy: 0.0813 - val_loss: 3.8323 - val_categorical_accuracy: 0.0798\n",
      "Epoch 140/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7218 - categorical_accuracy: 0.0877 - val_loss: 3.8647 - val_categorical_accuracy: 0.0751\n",
      "Epoch 141/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7311 - categorical_accuracy: 0.0849 - val_loss: 3.8858 - val_categorical_accuracy: 0.0775\n",
      "Epoch 142/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7084 - categorical_accuracy: 0.0879 - val_loss: 3.8324 - val_categorical_accuracy: 0.0805\n",
      "Epoch 143/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7207 - categorical_accuracy: 0.0866 - val_loss: 3.8810 - val_categorical_accuracy: 0.0778\n",
      "Epoch 144/150\n",
      "111/111 [==============================] - 104s 939ms/step - loss: 3.7332 - categorical_accuracy: 0.0843 - val_loss: 3.8446 - val_categorical_accuracy: 0.0834\n",
      "Epoch 145/150\n",
      "111/111 [==============================] - 105s 943ms/step - loss: 3.7224 - categorical_accuracy: 0.0884 - val_loss: 3.8438 - val_categorical_accuracy: 0.0811\n",
      "Epoch 146/150\n",
      "111/111 [==============================] - 105s 942ms/step - loss: 3.7261 - categorical_accuracy: 0.0883 - val_loss: 3.8372 - val_categorical_accuracy: 0.0775\n",
      "Epoch 147/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7083 - categorical_accuracy: 0.0852 - val_loss: 3.8489 - val_categorical_accuracy: 0.0814\n",
      "Epoch 148/150\n",
      "111/111 [==============================] - 104s 940ms/step - loss: 3.7206 - categorical_accuracy: 0.0922 - val_loss: 3.8679 - val_categorical_accuracy: 0.0821\n",
      "Epoch 149/150\n",
      "111/111 [==============================] - 105s 941ms/step - loss: 3.7213 - categorical_accuracy: 0.0902 - val_loss: 3.8515 - val_categorical_accuracy: 0.0821\n",
      "Epoch 150/150\n",
      "111/111 [==============================] - 104s 941ms/step - loss: 3.7135 - categorical_accuracy: 0.0904 - val_loss: 3.8737 - val_categorical_accuracy: 0.0741\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks = [history, tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## custom batch generator\n",
    "test_path = '/mnt/DataDisk/jodahr/data/Dogs/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not very elegant, but works\n",
    "def customGenerator(path, batch_size=32, target_size=(250,250), add_names=False):\n",
    "    '''Generator wich returns batches of img arrays. Alternatively you can add the filenames.'''\n",
    "    file_names = os.listdir(test_path)  # list of filenames\n",
    "    chunks = [file_names[x:x+batch_size] for x in range(0, len(file_names), batch_size)]  # divided into chunks\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        full_names = [test_path + '/' + file_name for file_name in chunk]  # create full filenames\n",
    "        img_batch = [load_img(full_name, target_size=target_size) for full_name in full_names]  # load image batches\n",
    "        arr_batch = np.empty(shape=(1,target_size[0],target_size[1],3))  # empty multidimensional numpy array\n",
    "        #arr_batch = []\n",
    "        # rescale arrays and combine them\n",
    "        for element in img_batch:\n",
    "            img_arr = np.expand_dims(img_to_array(element)/255., axis=0)\n",
    "            arr_batch = np.concatenate((arr_batch, img_arr), axis=0)\n",
    "        # yield\n",
    "        if add_names==False:\n",
    "            yield arr_batch[1:,:,:,:]\n",
    "        else:\n",
    "            yield (arr_batch[1:,:,:,:], chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = customGenerator(test_path, add_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 0.84705883,  0.76078433,  0.67843139],\n",
       "          [ 0.80392158,  0.5529412 ,  0.3019608 ],\n",
       "          [ 0.63921571,  0.3882353 ,  0.13725491],\n",
       "          ..., \n",
       "          [ 0.11764706,  0.05098039,  0.01960784],\n",
       "          [ 0.10980392,  0.05490196,  0.01960784],\n",
       "          [ 0.10980392,  0.05490196,  0.01960784]],\n",
       " \n",
       "         [[ 1.        ,  0.98039216,  0.89803922],\n",
       "          [ 0.78431374,  0.54901963,  0.30588236],\n",
       "          [ 0.78823531,  0.54901963,  0.3019608 ],\n",
       "          ..., \n",
       "          [ 0.11764706,  0.05098039,  0.01960784],\n",
       "          [ 0.10980392,  0.05490196,  0.01960784],\n",
       "          [ 0.10980392,  0.05490196,  0.01960784]],\n",
       " \n",
       "         [[ 1.        ,  0.92156863,  0.8392157 ],\n",
       "          [ 0.82352942,  0.59215689,  0.36470589],\n",
       "          [ 0.7647059 ,  0.52941179,  0.28627452],\n",
       "          ..., \n",
       "          [ 0.11764706,  0.05098039,  0.01960784],\n",
       "          [ 0.10980392,  0.05490196,  0.01960784],\n",
       "          [ 0.10980392,  0.05490196,  0.01960784]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.50980395,  0.34509805,  0.15686275],\n",
       "          [ 0.49803922,  0.33333334,  0.14509805],\n",
       "          [ 0.48235294,  0.31764707,  0.12941177],\n",
       "          ..., \n",
       "          [ 0.43137255,  0.25882354,  0.01960784],\n",
       "          [ 0.4627451 ,  0.28627452,  0.05490196],\n",
       "          [ 0.45490196,  0.27843139,  0.04705882]],\n",
       " \n",
       "         [[ 0.44313726,  0.27843139,  0.09019608],\n",
       "          [ 0.46666667,  0.3019608 ,  0.11372549],\n",
       "          [ 0.49019608,  0.32549021,  0.13725491],\n",
       "          ..., \n",
       "          [ 0.45882353,  0.27843139,  0.04705882],\n",
       "          [ 0.44705883,  0.28235295,  0.05490196],\n",
       "          [ 0.43921569,  0.27450982,  0.04705882]],\n",
       " \n",
       "         [[ 0.50588238,  0.34117648,  0.15294118],\n",
       "          [ 0.49019608,  0.32549021,  0.13725491],\n",
       "          [ 0.47058824,  0.30588236,  0.11764706],\n",
       "          ..., \n",
       "          [ 0.50980395,  0.32549021,  0.11372549],\n",
       "          [ 0.49803922,  0.33725491,  0.11764706],\n",
       "          [ 0.48627451,  0.32549021,  0.10588235]]],\n",
       " \n",
       " \n",
       "        [[[ 0.67058825,  0.81176472,  0.33333334],\n",
       "          [ 0.69803923,  0.83137256,  0.34901962],\n",
       "          [ 0.67450982,  0.81176472,  0.30980393],\n",
       "          ..., \n",
       "          [ 0.87450981,  0.97254902,  0.64313728],\n",
       "          [ 0.86274511,  0.92941177,  0.62352943],\n",
       "          [ 0.8392157 ,  0.90588236,  0.60000002]],\n",
       " \n",
       "         [[ 0.64705884,  0.78039217,  0.30980393],\n",
       "          [ 0.67450982,  0.80784315,  0.33333334],\n",
       "          [ 0.63529414,  0.77254903,  0.27843139],\n",
       "          ..., \n",
       "          [ 0.88235295,  0.98039216,  0.65098041],\n",
       "          [ 0.90196079,  0.96862745,  0.66274512],\n",
       "          [ 0.88235295,  0.94901961,  0.64313728]],\n",
       " \n",
       "         [[ 0.627451  ,  0.75686276,  0.3137255 ],\n",
       "          [ 0.65490198,  0.78431374,  0.33333334],\n",
       "          [ 0.65098041,  0.77254903,  0.3137255 ],\n",
       "          ..., \n",
       "          [ 0.87450981,  0.97647059,  0.627451  ],\n",
       "          [ 0.88235295,  0.95294118,  0.63137257],\n",
       "          [ 0.87058824,  0.94117647,  0.61960787]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.45490196,  0.52549022,  0.32156864],\n",
       "          [ 0.49019608,  0.55686277,  0.35294119],\n",
       "          [ 0.47450981,  0.52941179,  0.32156864],\n",
       "          ..., \n",
       "          [ 0.78039217,  0.81960785,  0.53333336],\n",
       "          [ 0.79215688,  0.81176472,  0.54901963],\n",
       "          [ 0.82352942,  0.84313726,  0.58039218]],\n",
       " \n",
       "         [[ 0.64705884,  0.57647061,  0.41960785],\n",
       "          [ 0.58823532,  0.52156866,  0.35294119],\n",
       "          [ 0.59607846,  0.52941179,  0.36078432],\n",
       "          ..., \n",
       "          [ 0.86666667,  0.89019608,  0.63921571],\n",
       "          [ 0.83529413,  0.8392157 ,  0.60392159],\n",
       "          [ 0.8392157 ,  0.84313726,  0.60784316]],\n",
       " \n",
       "         [[ 0.68235296,  0.57254905,  0.41960785],\n",
       "          [ 0.63921571,  0.52941179,  0.37254903],\n",
       "          [ 0.56470591,  0.45490196,  0.29803923],\n",
       "          ..., \n",
       "          [ 0.93725491,  0.96078432,  0.72549021],\n",
       "          [ 0.90196079,  0.90588236,  0.67843139],\n",
       "          [ 0.86274511,  0.86666667,  0.63921571]]],\n",
       " \n",
       " \n",
       "        [[[ 0.49019608,  0.4509804 ,  0.40392157],\n",
       "          [ 0.48627451,  0.45490196,  0.41176471],\n",
       "          [ 0.48627451,  0.45490196,  0.41176471],\n",
       "          ..., \n",
       "          [ 0.44705883,  0.30980393,  0.16078432],\n",
       "          [ 0.49803922,  0.35686275,  0.25490198],\n",
       "          [ 0.47058824,  0.32941177,  0.22745098]],\n",
       " \n",
       "         [[ 0.47450981,  0.44313726,  0.39215687],\n",
       "          [ 0.47843137,  0.44705883,  0.40392157],\n",
       "          [ 0.48627451,  0.4509804 ,  0.41568628],\n",
       "          ..., \n",
       "          [ 0.4627451 ,  0.32156864,  0.1882353 ],\n",
       "          [ 0.43921569,  0.29803923,  0.20392157],\n",
       "          [ 0.41176471,  0.27058825,  0.17647059]],\n",
       " \n",
       "         [[ 0.47058824,  0.43921569,  0.39607844],\n",
       "          [ 0.47450981,  0.44313726,  0.40000001],\n",
       "          [ 0.48235294,  0.44705883,  0.41176471],\n",
       "          ..., \n",
       "          [ 0.39215687,  0.24705882,  0.14117648],\n",
       "          [ 0.35294119,  0.21176471,  0.1254902 ],\n",
       "          [ 0.3764706 ,  0.23529412,  0.14901961]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.42352942,  0.38431373,  0.24705882],\n",
       "          [ 0.27450982,  0.27058825,  0.09803922],\n",
       "          [ 0.16078432,  0.17254902,  0.        ],\n",
       "          ..., \n",
       "          [ 0.2       ,  0.2       ,  0.06666667],\n",
       "          [ 0.07843138,  0.07058824,  0.        ],\n",
       "          [ 0.11372549,  0.10588235,  0.01568628]],\n",
       " \n",
       "         [[ 0.34509805,  0.29411766,  0.16078432],\n",
       "          [ 0.41176471,  0.40000001,  0.22352941],\n",
       "          [ 0.23921569,  0.23921569,  0.02745098],\n",
       "          ..., \n",
       "          [ 0.22352941,  0.21960784,  0.09803922],\n",
       "          [ 0.07843138,  0.07058824,  0.        ],\n",
       "          [ 0.13725491,  0.12941177,  0.04705882]],\n",
       " \n",
       "         [[ 0.35294119,  0.27843139,  0.14901961],\n",
       "          [ 0.23137255,  0.19607843,  0.02745098],\n",
       "          [ 0.42352942,  0.40392157,  0.1882353 ],\n",
       "          ..., \n",
       "          [ 0.28235295,  0.27843139,  0.16862746],\n",
       "          [ 0.06666667,  0.05490196,  0.        ],\n",
       "          [ 0.11764706,  0.10588235,  0.04705882]]],\n",
       " \n",
       " \n",
       "        ..., \n",
       "        [[[ 0.77254903,  0.88235295,  0.97647059],\n",
       "          [ 0.78431374,  0.89411765,  0.98823529],\n",
       "          [ 0.79215688,  0.90196079,  0.98823529],\n",
       "          ..., \n",
       "          [ 0.99215686,  0.99215686,  0.99215686],\n",
       "          [ 0.99215686,  0.99215686,  0.99215686],\n",
       "          [ 0.99215686,  0.99215686,  0.99215686]],\n",
       " \n",
       "         [[ 0.7764706 ,  0.88627452,  0.98039216],\n",
       "          [ 0.78431374,  0.89411765,  0.98039216],\n",
       "          [ 0.78823531,  0.89803922,  0.98431373],\n",
       "          ..., \n",
       "          [ 0.99215686,  0.99215686,  0.99215686],\n",
       "          [ 0.99215686,  0.99215686,  0.99215686],\n",
       "          [ 0.99215686,  0.99215686,  0.99215686]],\n",
       " \n",
       "         [[ 0.78039217,  0.89019608,  0.97647059],\n",
       "          [ 0.78823531,  0.89803922,  0.98431373],\n",
       "          [ 0.78431374,  0.89411765,  0.98039216],\n",
       "          ..., \n",
       "          [ 0.99215686,  0.99215686,  0.99215686],\n",
       "          [ 0.99215686,  0.99215686,  0.99215686],\n",
       "          [ 0.99215686,  0.99215686,  0.99215686]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.21176471,  0.23921569,  0.16862746],\n",
       "          [ 0.2       ,  0.22745098,  0.15686275],\n",
       "          [ 0.19607843,  0.22352941,  0.16078432],\n",
       "          ..., \n",
       "          [ 0.27058825,  0.32941177,  0.30980393],\n",
       "          [ 0.23529412,  0.28235295,  0.26666668],\n",
       "          [ 0.23137255,  0.27843139,  0.27058825]],\n",
       " \n",
       "         [[ 0.22352941,  0.25098041,  0.18039216],\n",
       "          [ 0.21960784,  0.24705882,  0.17647059],\n",
       "          [ 0.22745098,  0.25490198,  0.19215687],\n",
       "          ..., \n",
       "          [ 0.31764707,  0.3764706 ,  0.35686275],\n",
       "          [ 0.24705882,  0.29411766,  0.27843139],\n",
       "          [ 0.21176471,  0.25882354,  0.25098041]],\n",
       " \n",
       "         [[ 0.21960784,  0.24705882,  0.17647059],\n",
       "          [ 0.21960784,  0.24705882,  0.17647059],\n",
       "          [ 0.23921569,  0.26666668,  0.20392157],\n",
       "          ..., \n",
       "          [ 0.28627452,  0.34509805,  0.32549021],\n",
       "          [ 0.26274511,  0.30980393,  0.29411766],\n",
       "          [ 0.23137255,  0.27843139,  0.27058825]]],\n",
       " \n",
       " \n",
       "        [[[ 0.63137257,  0.627451  ,  0.61960787],\n",
       "          [ 0.60392159,  0.60000002,  0.58431375],\n",
       "          [ 0.61176473,  0.60784316,  0.58823532],\n",
       "          ..., \n",
       "          [ 0.50980395,  0.5411765 ,  0.31764707],\n",
       "          [ 0.50980395,  0.5411765 ,  0.31764707],\n",
       "          [ 0.49411765,  0.52549022,  0.3019608 ]],\n",
       " \n",
       "         [[ 0.63137257,  0.627451  ,  0.61960787],\n",
       "          [ 0.60392159,  0.60000002,  0.58431375],\n",
       "          [ 0.61176473,  0.60784316,  0.58823532],\n",
       "          ..., \n",
       "          [ 0.50980395,  0.5411765 ,  0.31764707],\n",
       "          [ 0.50980395,  0.5411765 ,  0.31764707],\n",
       "          [ 0.49411765,  0.52549022,  0.3019608 ]],\n",
       " \n",
       "         [[ 0.627451  ,  0.62352943,  0.6156863 ],\n",
       "          [ 0.60392159,  0.60000002,  0.58431375],\n",
       "          [ 0.61176473,  0.60784316,  0.58823532],\n",
       "          ..., \n",
       "          [ 0.50588238,  0.53725493,  0.3137255 ],\n",
       "          [ 0.50588238,  0.53725493,  0.3137255 ],\n",
       "          [ 0.49803922,  0.52941179,  0.30588236]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.34509805,  0.32941177,  0.28235295],\n",
       "          [ 0.32941177,  0.3137255 ,  0.26666668],\n",
       "          [ 0.29803923,  0.28235295,  0.23529412],\n",
       "          ..., \n",
       "          [ 0.38039216,  0.3882353 ,  0.23137255],\n",
       "          [ 0.38039216,  0.3882353 ,  0.23137255],\n",
       "          [ 0.38431373,  0.39215687,  0.23529412]],\n",
       " \n",
       "         [[ 0.30980393,  0.29411766,  0.24705882],\n",
       "          [ 0.28235295,  0.26666668,  0.21960784],\n",
       "          [ 0.25490198,  0.23921569,  0.19215687],\n",
       "          ..., \n",
       "          [ 0.39215687,  0.39215687,  0.24313726],\n",
       "          [ 0.39215687,  0.39215687,  0.24313726],\n",
       "          [ 0.40000001,  0.40000001,  0.25098041]],\n",
       " \n",
       "         [[ 0.33333334,  0.31764707,  0.27058825],\n",
       "          [ 0.29019609,  0.27450982,  0.22745098],\n",
       "          [ 0.24705882,  0.23137255,  0.18431373],\n",
       "          ..., \n",
       "          [ 0.41176471,  0.41176471,  0.26274511],\n",
       "          [ 0.41176471,  0.41176471,  0.26274511],\n",
       "          [ 0.41568628,  0.41568628,  0.26666668]]],\n",
       " \n",
       " \n",
       "        [[[ 0.        ,  0.00392157,  0.        ],\n",
       "          [ 0.04705882,  0.05098039,  0.01960784],\n",
       "          [ 0.05098039,  0.05490196,  0.02352941],\n",
       "          ..., \n",
       "          [ 0.03529412,  0.        ,  0.01176471],\n",
       "          [ 0.03137255,  0.        ,  0.00392157],\n",
       "          [ 0.01176471,  0.00392157,  0.00784314]],\n",
       " \n",
       "         [[ 0.03921569,  0.04313726,  0.01176471],\n",
       "          [ 0.15294118,  0.15686275,  0.1254902 ],\n",
       "          [ 0.14901961,  0.15294118,  0.12156863],\n",
       "          ..., \n",
       "          [ 0.13333334,  0.09803922,  0.10980392],\n",
       "          [ 0.14117648,  0.09803922,  0.11372549],\n",
       "          [ 0.03137255,  0.02352941,  0.02745098]],\n",
       " \n",
       "         [[ 0.05098039,  0.05490196,  0.02352941],\n",
       "          [ 0.18039216,  0.18431373,  0.15294118],\n",
       "          [ 0.13725491,  0.14117648,  0.10980392],\n",
       "          ..., \n",
       "          [ 0.09019608,  0.05490196,  0.06666667],\n",
       "          [ 0.09019608,  0.04705882,  0.0627451 ],\n",
       "          [ 0.03921569,  0.03137255,  0.03529412]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.05490196,  0.05882353,  0.07450981],\n",
       "          [ 0.80392158,  0.80784315,  0.82352942],\n",
       "          [ 0.78823531,  0.78431374,  0.80784315],\n",
       "          ..., \n",
       "          [ 0.65882355,  0.70588237,  0.61176473],\n",
       "          [ 0.22745098,  0.27450982,  0.18039216],\n",
       "          [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.00392157,  0.00784314,  0.02352941],\n",
       "          [ 0.65882355,  0.66274512,  0.68235296],\n",
       "          [ 0.7647059 ,  0.76078433,  0.79215688],\n",
       "          ..., \n",
       "          [ 0.50196081,  0.5529412 ,  0.4509804 ],\n",
       "          [ 0.25882354,  0.30980393,  0.20784314],\n",
       "          [ 0.        ,  0.        ,  0.        ]],\n",
       " \n",
       "         [[ 0.00392157,  0.        ,  0.        ],\n",
       "          [ 0.01960784,  0.01568628,  0.00784314],\n",
       "          [ 0.01960784,  0.01176471,  0.01568628],\n",
       "          ..., \n",
       "          [ 0.14117648,  0.14117648,  0.13333334],\n",
       "          [ 0.00784314,  0.00784314,  0.        ],\n",
       "          [ 0.        ,  0.00392157,  0.        ]]]]),\n",
       " ['2ce015d0d017c595bb64627a5749e3bd.jpg',\n",
       "  '5bad43e776606caab0912c9e7f0e75ff.jpg',\n",
       "  '89357a5cef0812f2ba888041de62a243.jpg',\n",
       "  'b8da90f454f62fb33c83715a404aca3b.jpg',\n",
       "  '000621fb3cbb32d8935728e48679680e.jpg',\n",
       "  '00102ee9d8eb90812350685311fe5890.jpg',\n",
       "  '0012a730dfa437f5f3613fb75efcd4ce.jpg',\n",
       "  '001510bc8570bbeee98c8d80c8a95ec1.jpg',\n",
       "  '001a5f3114548acdefa3d4da05474c2e.jpg',\n",
       "  '00225dcd3e4d2410dd53239f95c0352f.jpg',\n",
       "  '002c2a3117c2193b4d26400ce431eebd.jpg',\n",
       "  '002c58d413a521ae8d1a5daeb35fc803.jpg',\n",
       "  '002f80396f1e3db687c5932d7978b196.jpg',\n",
       "  '0036c6bcec6031be9e62a257b1c3c442.jpg',\n",
       "  '0041940322116ae58c38130f5a6f71f9.jpg',\n",
       "  '0042d6bf3e5f3700865886db32689436.jpg',\n",
       "  '00485d47de966a9437ad3b33ac193b6f.jpg',\n",
       "  '00496f65de6cc319145ce97bd6e90360.jpg',\n",
       "  '004bf14426d1a830d459a9e0c0721309.jpg',\n",
       "  '004c3721eb88358f462cdcec6b2380b7.jpg',\n",
       "  '00559f56aab7e0a7749220f6aed65162.jpg',\n",
       "  '005b281f1a4d6f29d527c9585e9bd33c.jpg',\n",
       "  '005b6c6c76fefd6b458ef6fb6e54da6e.jpg',\n",
       "  '006870b49353779b25eeb91fed43c31a.jpg',\n",
       "  '0068f3a21b159ece126a28580cdad7a0.jpg',\n",
       "  '0069b1cc4546fc98f84f981bf9a0696a.jpg',\n",
       "  '0077bc3c63486ff09d3774d956af8f76.jpg',\n",
       "  '00780e5d2bf4f7e4b5f96d08ddde669a.jpg',\n",
       "  '0081831ceb49cd64212c32b884036b82.jpg',\n",
       "  '00846c0edd5aa4f10ee5e9b84d7310a6.jpg',\n",
       "  '0092bd9e90a13403373fc0e9e1218938.jpg',\n",
       "  '009a3c4f6626e4750f74ceb8e8ed8760.jpg'])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [cls for cls in train_generator.class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affenpinscher',\n",
       " 'afghan_hound',\n",
       " 'african_hunting_dog',\n",
       " 'airedale',\n",
       " 'american_staffordshire_terrier',\n",
       " 'appenzeller',\n",
       " 'australian_terrier',\n",
       " 'basenji',\n",
       " 'basset',\n",
       " 'beagle',\n",
       " 'bedlington_terrier',\n",
       " 'bernese_mountain_dog',\n",
       " 'black-and-tan_coonhound',\n",
       " 'blenheim_spaniel',\n",
       " 'bloodhound',\n",
       " 'bluetick',\n",
       " 'border_collie',\n",
       " 'border_terrier',\n",
       " 'borzoi',\n",
       " 'boston_bull',\n",
       " 'bouvier_des_flandres',\n",
       " 'boxer',\n",
       " 'brabancon_griffon',\n",
       " 'briard',\n",
       " 'brittany_spaniel',\n",
       " 'bull_mastiff',\n",
       " 'cairn',\n",
       " 'cardigan',\n",
       " 'chesapeake_bay_retriever',\n",
       " 'chihuahua',\n",
       " 'chow',\n",
       " 'clumber',\n",
       " 'cocker_spaniel',\n",
       " 'collie',\n",
       " 'curly-coated_retriever',\n",
       " 'dandie_dinmont',\n",
       " 'dhole',\n",
       " 'dingo',\n",
       " 'doberman',\n",
       " 'english_foxhound',\n",
       " 'english_setter',\n",
       " 'english_springer',\n",
       " 'entlebucher',\n",
       " 'eskimo_dog',\n",
       " 'flat-coated_retriever',\n",
       " 'french_bulldog',\n",
       " 'german_shepherd',\n",
       " 'german_short-haired_pointer',\n",
       " 'giant_schnauzer',\n",
       " 'golden_retriever',\n",
       " 'gordon_setter',\n",
       " 'great_dane',\n",
       " 'great_pyrenees',\n",
       " 'greater_swiss_mountain_dog',\n",
       " 'groenendael',\n",
       " 'ibizan_hound',\n",
       " 'irish_setter',\n",
       " 'irish_terrier',\n",
       " 'irish_water_spaniel',\n",
       " 'irish_wolfhound',\n",
       " 'italian_greyhound',\n",
       " 'japanese_spaniel',\n",
       " 'keeshond',\n",
       " 'kelpie',\n",
       " 'kerry_blue_terrier',\n",
       " 'komondor',\n",
       " 'kuvasz',\n",
       " 'labrador_retriever',\n",
       " 'lakeland_terrier',\n",
       " 'leonberg',\n",
       " 'lhasa',\n",
       " 'malamute',\n",
       " 'malinois',\n",
       " 'maltese_dog',\n",
       " 'mexican_hairless',\n",
       " 'miniature_pinscher',\n",
       " 'miniature_poodle',\n",
       " 'miniature_schnauzer',\n",
       " 'newfoundland',\n",
       " 'norfolk_terrier',\n",
       " 'norwegian_elkhound',\n",
       " 'norwich_terrier',\n",
       " 'old_english_sheepdog',\n",
       " 'otterhound',\n",
       " 'papillon',\n",
       " 'pekinese',\n",
       " 'pembroke',\n",
       " 'pomeranian',\n",
       " 'pug',\n",
       " 'redbone',\n",
       " 'rhodesian_ridgeback',\n",
       " 'rottweiler',\n",
       " 'saint_bernard',\n",
       " 'saluki',\n",
       " 'samoyed',\n",
       " 'schipperke',\n",
       " 'scotch_terrier',\n",
       " 'scottish_deerhound',\n",
       " 'sealyham_terrier',\n",
       " 'shetland_sheepdog',\n",
       " 'shih-tzu',\n",
       " 'siberian_husky',\n",
       " 'silky_terrier',\n",
       " 'soft-coated_wheaten_terrier',\n",
       " 'staffordshire_bullterrier',\n",
       " 'standard_poodle',\n",
       " 'standard_schnauzer',\n",
       " 'sussex_spaniel',\n",
       " 'tibetan_mastiff',\n",
       " 'tibetan_terrier',\n",
       " 'toy_poodle',\n",
       " 'toy_terrier',\n",
       " 'vizsla',\n",
       " 'walker_hound',\n",
       " 'weimaraner',\n",
       " 'welsh_springer_spaniel',\n",
       " 'west_highland_white_terrier',\n",
       " 'whippet',\n",
       " 'wire-haired_fox_terrier',\n",
       " 'yorkshire_terrier']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.66719801e-03,   1.36663876e-02,   9.29446614e-05, ...,\n",
       "          1.34669526e-05,   4.20302246e-03,   3.58942925e-04],\n",
       "       [  1.90508254e-02,   2.92434283e-02,   1.61392862e-04, ...,\n",
       "          3.28782335e-07,   1.53485574e-02,   2.59571169e-02],\n",
       "       [  2.83657664e-05,   1.34259956e-02,   1.61422722e-05, ...,\n",
       "          2.22239745e-04,   2.10064813e-03,   1.31909736e-04],\n",
       "       ..., \n",
       "       [  1.85186355e-09,   1.73129934e-06,   1.91986590e-04, ...,\n",
       "          4.66543213e-02,   3.26589688e-05,   4.03094758e-09],\n",
       "       [  1.64215191e-04,   6.60411939e-02,   5.29717654e-05, ...,\n",
       "          2.54850274e-05,   8.80080368e-03,   3.71290557e-03],\n",
       "       [  1.73287913e-02,   1.78360716e-02,   8.16231873e-03, ...,\n",
       "          1.24997168e-03,   1.16306208e-02,   1.38936155e-02]], dtype=float32)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submission(my_generator_tuple, model, class_names):\n",
    "    result = pd.DataFrame()\n",
    "    predictions = []\n",
    "    names = []\n",
    "    cols = ['id'] + class_names\n",
    "    for element in my_generator_tuple:\n",
    "        predictions = model.predict(element[0])\n",
    "        names = element[1]\n",
    "        temp = pd.DataFrame(predictions)\n",
    "        temp.columns = class_names\n",
    "        temp['names'] = names\n",
    "        result = pd.concat([result, temp])\n",
    "    #result.columns = class_names\n",
    "    #result['names'] = names\n",
    "    result['id'] = result.names.apply(lambda x: x.split('.jpg')[0])\n",
    "    return result[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = customGenerator(test_path, add_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = get_submission(gen, model, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10357 entries, 0 to 20\n",
      "Columns: 121 entries, id to yorkshire_terrier\n",
      "dtypes: float32(120), object(1)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2ce015d0d017c595bb64627a5749e3bd</td>\n",
       "      <td>1.157716e-02</td>\n",
       "      <td>4.835804e-03</td>\n",
       "      <td>0.027818</td>\n",
       "      <td>0.032993</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>6.514817e-03</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>...</td>\n",
       "      <td>8.090748e-03</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>1.536332e-03</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>3.407072e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5bad43e776606caab0912c9e7f0e75ff</td>\n",
       "      <td>9.511627e-04</td>\n",
       "      <td>2.147182e-02</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>2.682158e-03</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.009189</td>\n",
       "      <td>...</td>\n",
       "      <td>9.561103e-03</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.020222</td>\n",
       "      <td>7.231265e-03</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>6.476256e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89357a5cef0812f2ba888041de62a243</td>\n",
       "      <td>7.265832e-06</td>\n",
       "      <td>6.479005e-04</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>5.336166e-07</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.010301</td>\n",
       "      <td>...</td>\n",
       "      <td>2.225210e-04</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.070151</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>1.981079e-07</td>\n",
       "      <td>0.041645</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>4.121411e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b8da90f454f62fb33c83715a404aca3b</td>\n",
       "      <td>1.803837e-09</td>\n",
       "      <td>2.629415e-07</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.043727</td>\n",
       "      <td>0.023229</td>\n",
       "      <td>2.197491e-07</td>\n",
       "      <td>0.057545</td>\n",
       "      <td>0.023177</td>\n",
       "      <td>...</td>\n",
       "      <td>5.995201e-07</td>\n",
       "      <td>0.057286</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>0.028716</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>3.000939e-08</td>\n",
       "      <td>0.025864</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>3.689647e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
       "      <td>7.988258e-06</td>\n",
       "      <td>2.821555e-02</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.007749</td>\n",
       "      <td>1.309027e-05</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.024533</td>\n",
       "      <td>...</td>\n",
       "      <td>8.380160e-04</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.083709</td>\n",
       "      <td>7.171297e-05</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>3.975941e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  affenpinscher  afghan_hound  \\\n",
       "0  2ce015d0d017c595bb64627a5749e3bd   1.157716e-02  4.835804e-03   \n",
       "1  5bad43e776606caab0912c9e7f0e75ff   9.511627e-04  2.147182e-02   \n",
       "2  89357a5cef0812f2ba888041de62a243   7.265832e-06  6.479005e-04   \n",
       "3  b8da90f454f62fb33c83715a404aca3b   1.803837e-09  2.629415e-07   \n",
       "4  000621fb3cbb32d8935728e48679680e   7.988258e-06  2.821555e-02   \n",
       "\n",
       "   african_hunting_dog  airedale  american_staffordshire_terrier  appenzeller  \\\n",
       "0             0.027818  0.032993                        0.007021     0.002110   \n",
       "1             0.004653  0.005561                        0.004169     0.010553   \n",
       "2             0.000827  0.003985                        0.013822     0.000683   \n",
       "3             0.001661  0.000043                        0.043727     0.023229   \n",
       "4             0.000588  0.001447                        0.006184     0.007749   \n",
       "\n",
       "   australian_terrier   basenji    basset        ...            toy_poodle  \\\n",
       "0        6.514817e-03  0.006022  0.000925        ...          8.090748e-03   \n",
       "1        2.682158e-03  0.002632  0.009189        ...          9.561103e-03   \n",
       "2        5.336166e-07  0.001787  0.010301        ...          2.225210e-04   \n",
       "3        2.197491e-07  0.057545  0.023177        ...          5.995201e-07   \n",
       "4        1.309027e-05  0.000572  0.024533        ...          8.380160e-04   \n",
       "\n",
       "   toy_terrier    vizsla  walker_hound  weimaraner  welsh_springer_spaniel  \\\n",
       "0     0.002122  0.006315      0.000318    0.002031                0.000304   \n",
       "1     0.006851  0.001696      0.000436    0.001779                0.020222   \n",
       "2     0.000009  0.070151      0.005030    0.066420                0.002201   \n",
       "3     0.057286  0.008618      0.028716    0.008926                0.000309   \n",
       "4     0.001081  0.004419      0.003700    0.008177                0.083709   \n",
       "\n",
       "   west_highland_white_terrier   whippet  wire-haired_fox_terrier  \\\n",
       "0                 1.536332e-03  0.007216                 0.007534   \n",
       "1                 7.231265e-03  0.004216                 0.009269   \n",
       "2                 1.981079e-07  0.041645                 0.000604   \n",
       "3                 3.000939e-08  0.025864                 0.000128   \n",
       "4                 7.171297e-05  0.006364                 0.004820   \n",
       "\n",
       "   yorkshire_terrier  \n",
       "0       3.407072e-03  \n",
       "1       6.476256e-03  \n",
       "2       4.121411e-06  \n",
       "3       3.689647e-08  \n",
       "4       3.975941e-04  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub.to_csv('test_20180325.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>...</th>\n",
       "      <th>toy_poodle</th>\n",
       "      <th>toy_terrier</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ffb3a78e4a162c173219194687eb6054</td>\n",
       "      <td>4.964123e-03</td>\n",
       "      <td>2.292066e-02</td>\n",
       "      <td>0.020423</td>\n",
       "      <td>0.024829</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>7.997761e-03</td>\n",
       "      <td>4.293246e-03</td>\n",
       "      <td>4.821258e-03</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>3.733022e-03</td>\n",
       "      <td>9.822696e-03</td>\n",
       "      <td>2.508722e-03</td>\n",
       "      <td>6.091225e-03</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>1.757284e-03</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>6.989223e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ffb55dbaa32939c109ef42df0668e077</td>\n",
       "      <td>3.641260e-06</td>\n",
       "      <td>1.329235e-05</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.028737</td>\n",
       "      <td>1.429782e-02</td>\n",
       "      <td>2.931678e-05</td>\n",
       "      <td>3.431739e-02</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.943945e-02</td>\n",
       "      <td>1.640671e-02</td>\n",
       "      <td>1.638699e-02</td>\n",
       "      <td>1.126600e-02</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>1.912240e-06</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>4.937038e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ffb68ded4a2247b3c011840ece0a605c</td>\n",
       "      <td>1.765690e-04</td>\n",
       "      <td>1.115593e-02</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>3.952796e-05</td>\n",
       "      <td>1.223583e-03</td>\n",
       "      <td>1.371287e-07</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>1.410393e-04</td>\n",
       "      <td>4.843663e-07</td>\n",
       "      <td>5.266557e-15</td>\n",
       "      <td>1.066823e-08</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>1.352255e-02</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>4.440775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ffb8bceeac5b3f587f67391ad346d454</td>\n",
       "      <td>7.390619e-05</td>\n",
       "      <td>1.649890e-05</td>\n",
       "      <td>0.032647</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>6.549921e-03</td>\n",
       "      <td>2.735183e-03</td>\n",
       "      <td>5.678755e-02</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.220213e-02</td>\n",
       "      <td>5.620310e-05</td>\n",
       "      <td>7.477730e-05</td>\n",
       "      <td>1.493562e-05</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>4.612583e-04</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>1.800847e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ffbb6663b38e903dbd1efa5dce2d0bbb</td>\n",
       "      <td>7.302277e-06</td>\n",
       "      <td>2.201247e-02</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>9.496404e-05</td>\n",
       "      <td>9.247853e-05</td>\n",
       "      <td>1.696455e-07</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>2.265531e-04</td>\n",
       "      <td>3.700886e-06</td>\n",
       "      <td>6.313635e-12</td>\n",
       "      <td>9.797548e-07</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>2.832103e-03</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>1.196462e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ffbcda9eb84339cc5be15fd9900596a2</td>\n",
       "      <td>3.833268e-05</td>\n",
       "      <td>1.945516e-04</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>5.988509e-03</td>\n",
       "      <td>2.341162e-05</td>\n",
       "      <td>1.271904e-02</td>\n",
       "      <td>0.015437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>1.074401e-03</td>\n",
       "      <td>4.326552e-02</td>\n",
       "      <td>1.679385e-02</td>\n",
       "      <td>3.652578e-02</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>2.180068e-06</td>\n",
       "      <td>0.039987</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>1.683983e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ffbcf032231bb0b025f9070d42ab7e8f</td>\n",
       "      <td>8.283211e-09</td>\n",
       "      <td>9.892879e-04</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>9.863685e-02</td>\n",
       "      <td>7.200327e-07</td>\n",
       "      <td>4.649433e-03</td>\n",
       "      <td>0.034677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.663580e-02</td>\n",
       "      <td>8.847610e-05</td>\n",
       "      <td>3.564705e-03</td>\n",
       "      <td>1.160738e-04</td>\n",
       "      <td>0.057227</td>\n",
       "      <td>7.832055e-06</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>1.264341e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ffc0233904f4d03afe1484be791e09d6</td>\n",
       "      <td>2.613924e-02</td>\n",
       "      <td>1.129146e-02</td>\n",
       "      <td>0.014004</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>3.330973e-04</td>\n",
       "      <td>1.560937e-02</td>\n",
       "      <td>3.172185e-04</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016011</td>\n",
       "      <td>1.055968e-03</td>\n",
       "      <td>5.933307e-04</td>\n",
       "      <td>2.963574e-07</td>\n",
       "      <td>8.284627e-05</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>8.990199e-03</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>1.261263e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ffd06687c72445b0c6e8a130a0a8711a</td>\n",
       "      <td>6.481498e-05</td>\n",
       "      <td>2.849161e-02</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>2.642561e-04</td>\n",
       "      <td>4.624598e-04</td>\n",
       "      <td>1.848259e-06</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014121</td>\n",
       "      <td>5.202889e-04</td>\n",
       "      <td>2.934717e-05</td>\n",
       "      <td>3.126022e-09</td>\n",
       "      <td>1.559910e-05</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>5.771452e-03</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>2.824786e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ffd304c521f43819f3824177fd9efeb0</td>\n",
       "      <td>2.801040e-07</td>\n",
       "      <td>9.948320e-06</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.028450</td>\n",
       "      <td>9.637496e-03</td>\n",
       "      <td>7.541211e-07</td>\n",
       "      <td>1.616295e-02</td>\n",
       "      <td>0.020645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>3.296572e-03</td>\n",
       "      <td>3.807002e-02</td>\n",
       "      <td>2.921159e-02</td>\n",
       "      <td>3.844613e-02</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>5.946529e-08</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>5.109840e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ffd3ce0566df4be8049c767a329faaf7</td>\n",
       "      <td>2.103784e-02</td>\n",
       "      <td>1.541601e-02</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.032695</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>1.966932e-04</td>\n",
       "      <td>7.953356e-03</td>\n",
       "      <td>1.787785e-04</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>3.693861e-04</td>\n",
       "      <td>1.533608e-03</td>\n",
       "      <td>6.215695e-07</td>\n",
       "      <td>3.683519e-04</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>4.893063e-03</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>7.054249e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ffd87c3e44faa0e3ee5fbbdc4c63b59b</td>\n",
       "      <td>3.799532e-08</td>\n",
       "      <td>6.205879e-07</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.034015</td>\n",
       "      <td>4.438528e-03</td>\n",
       "      <td>1.311200e-07</td>\n",
       "      <td>2.277971e-02</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.244790e-03</td>\n",
       "      <td>4.381808e-02</td>\n",
       "      <td>1.701756e-02</td>\n",
       "      <td>2.918422e-02</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>4.553374e-09</td>\n",
       "      <td>0.051081</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>2.599339e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ffe2315cf566e039516f5a4a5e52ff1b</td>\n",
       "      <td>3.095911e-04</td>\n",
       "      <td>3.629531e-02</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.008863</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>9.317582e-03</td>\n",
       "      <td>2.288884e-04</td>\n",
       "      <td>1.817758e-03</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>1.526182e-03</td>\n",
       "      <td>1.097768e-02</td>\n",
       "      <td>5.616920e-03</td>\n",
       "      <td>1.279299e-02</td>\n",
       "      <td>0.045393</td>\n",
       "      <td>2.750939e-04</td>\n",
       "      <td>0.010761</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>1.880500e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ffe42f4b4c50d4f18c2b34500f391152</td>\n",
       "      <td>3.745136e-05</td>\n",
       "      <td>1.625172e-03</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.025587</td>\n",
       "      <td>1.848778e-02</td>\n",
       "      <td>1.448244e-04</td>\n",
       "      <td>2.118008e-02</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>1.572453e-02</td>\n",
       "      <td>1.754687e-02</td>\n",
       "      <td>1.817414e-02</td>\n",
       "      <td>2.289093e-02</td>\n",
       "      <td>0.012304</td>\n",
       "      <td>1.711656e-04</td>\n",
       "      <td>0.028274</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>2.269947e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ffe563b1b8c0dcd0797c4362c6754b96</td>\n",
       "      <td>2.200269e-06</td>\n",
       "      <td>1.188414e-04</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.033527</td>\n",
       "      <td>1.614716e-02</td>\n",
       "      <td>1.798368e-05</td>\n",
       "      <td>2.839987e-02</td>\n",
       "      <td>0.026575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>1.290696e-02</td>\n",
       "      <td>2.299764e-02</td>\n",
       "      <td>2.403040e-02</td>\n",
       "      <td>2.755640e-02</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>1.050699e-05</td>\n",
       "      <td>0.037192</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>1.322103e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ffe9717b7937c262f849416976f7620a</td>\n",
       "      <td>5.292931e-06</td>\n",
       "      <td>4.562984e-03</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.024261</td>\n",
       "      <td>1.641616e-02</td>\n",
       "      <td>8.848020e-06</td>\n",
       "      <td>9.150978e-03</td>\n",
       "      <td>0.032366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>2.916747e-03</td>\n",
       "      <td>2.206880e-02</td>\n",
       "      <td>2.449260e-02</td>\n",
       "      <td>3.682960e-02</td>\n",
       "      <td>0.032054</td>\n",
       "      <td>2.402682e-05</td>\n",
       "      <td>0.027020</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>1.000467e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ffeda8623d4eee33c6d1156a2ecbfcf8</td>\n",
       "      <td>4.315590e-03</td>\n",
       "      <td>6.654275e-03</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.031743</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>4.626315e-07</td>\n",
       "      <td>4.807195e-05</td>\n",
       "      <td>6.311876e-06</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020229</td>\n",
       "      <td>4.429776e-08</td>\n",
       "      <td>1.953201e-03</td>\n",
       "      <td>5.970971e-07</td>\n",
       "      <td>7.273422e-04</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.714454e-05</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>9.099605e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fff1ec9e6e413275984966f745a313b0</td>\n",
       "      <td>4.788198e-08</td>\n",
       "      <td>7.343311e-05</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.035869</td>\n",
       "      <td>2.741991e-02</td>\n",
       "      <td>2.933388e-06</td>\n",
       "      <td>3.477264e-02</td>\n",
       "      <td>0.032344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.283910e-02</td>\n",
       "      <td>9.710406e-03</td>\n",
       "      <td>2.691901e-02</td>\n",
       "      <td>1.753996e-02</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>8.038262e-06</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>3.953107e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fff74b59b758bbbf13a5793182a9bbe4</td>\n",
       "      <td>3.857945e-03</td>\n",
       "      <td>3.024805e-03</td>\n",
       "      <td>0.014512</td>\n",
       "      <td>0.026762</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>1.954159e-03</td>\n",
       "      <td>1.109531e-03</td>\n",
       "      <td>8.891254e-03</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>5.504606e-04</td>\n",
       "      <td>2.367129e-02</td>\n",
       "      <td>1.872352e-03</td>\n",
       "      <td>1.130670e-02</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>3.038915e-04</td>\n",
       "      <td>0.025274</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>6.529735e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fff7d50d848e8014ac1e9172dc6762a3</td>\n",
       "      <td>1.437676e-05</td>\n",
       "      <td>2.366622e-02</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>1.519336e-02</td>\n",
       "      <td>1.394305e-04</td>\n",
       "      <td>6.569310e-04</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>5.813285e-03</td>\n",
       "      <td>3.976177e-04</td>\n",
       "      <td>3.323524e-04</td>\n",
       "      <td>6.206629e-04</td>\n",
       "      <td>0.046134</td>\n",
       "      <td>1.564025e-03</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>1.575902e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fffbff22c1f51e3dc80c4bf04089545b</td>\n",
       "      <td>2.789355e-04</td>\n",
       "      <td>3.242578e-02</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.639099e-07</td>\n",
       "      <td>1.866699e-04</td>\n",
       "      <td>1.337407e-09</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>1.476515e-06</td>\n",
       "      <td>6.700903e-07</td>\n",
       "      <td>1.464823e-13</td>\n",
       "      <td>7.781105e-07</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>1.204357e-03</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>1.080963e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  affenpinscher  afghan_hound  \\\n",
       "0   ffb3a78e4a162c173219194687eb6054   4.964123e-03  2.292066e-02   \n",
       "1   ffb55dbaa32939c109ef42df0668e077   3.641260e-06  1.329235e-05   \n",
       "2   ffb68ded4a2247b3c011840ece0a605c   1.765690e-04  1.115593e-02   \n",
       "3   ffb8bceeac5b3f587f67391ad346d454   7.390619e-05  1.649890e-05   \n",
       "4   ffbb6663b38e903dbd1efa5dce2d0bbb   7.302277e-06  2.201247e-02   \n",
       "5   ffbcda9eb84339cc5be15fd9900596a2   3.833268e-05  1.945516e-04   \n",
       "6   ffbcf032231bb0b025f9070d42ab7e8f   8.283211e-09  9.892879e-04   \n",
       "7   ffc0233904f4d03afe1484be791e09d6   2.613924e-02  1.129146e-02   \n",
       "8   ffd06687c72445b0c6e8a130a0a8711a   6.481498e-05  2.849161e-02   \n",
       "9   ffd304c521f43819f3824177fd9efeb0   2.801040e-07  9.948320e-06   \n",
       "10  ffd3ce0566df4be8049c767a329faaf7   2.103784e-02  1.541601e-02   \n",
       "11  ffd87c3e44faa0e3ee5fbbdc4c63b59b   3.799532e-08  6.205879e-07   \n",
       "12  ffe2315cf566e039516f5a4a5e52ff1b   3.095911e-04  3.629531e-02   \n",
       "13  ffe42f4b4c50d4f18c2b34500f391152   3.745136e-05  1.625172e-03   \n",
       "14  ffe563b1b8c0dcd0797c4362c6754b96   2.200269e-06  1.188414e-04   \n",
       "15  ffe9717b7937c262f849416976f7620a   5.292931e-06  4.562984e-03   \n",
       "16  ffeda8623d4eee33c6d1156a2ecbfcf8   4.315590e-03  6.654275e-03   \n",
       "17  fff1ec9e6e413275984966f745a313b0   4.788198e-08  7.343311e-05   \n",
       "18  fff74b59b758bbbf13a5793182a9bbe4   3.857945e-03  3.024805e-03   \n",
       "19  fff7d50d848e8014ac1e9172dc6762a3   1.437676e-05  2.366622e-02   \n",
       "20  fffbff22c1f51e3dc80c4bf04089545b   2.789355e-04  3.242578e-02   \n",
       "\n",
       "    african_hunting_dog  airedale  american_staffordshire_terrier  \\\n",
       "0              0.020423  0.024829                        0.007781   \n",
       "1              0.011611  0.001259                        0.028737   \n",
       "2              0.000057  0.000465                        0.000027   \n",
       "3              0.032647  0.000936                        0.004391   \n",
       "4              0.000024  0.000182                        0.000104   \n",
       "5              0.007154  0.005106                        0.023243   \n",
       "6              0.000084  0.000022                        0.004493   \n",
       "7              0.014004  0.032468                        0.001269   \n",
       "8              0.000125  0.000666                        0.000328   \n",
       "9              0.002845  0.000696                        0.028450   \n",
       "10             0.008996  0.032695                        0.001641   \n",
       "11             0.001883  0.000358                        0.034015   \n",
       "12             0.004283  0.008863                        0.008525   \n",
       "13             0.007161  0.002961                        0.025587   \n",
       "14             0.004872  0.001157                        0.033527   \n",
       "15             0.001994  0.001697                        0.024261   \n",
       "16             0.000394  0.031743                        0.000400   \n",
       "17             0.001325  0.000160                        0.035869   \n",
       "18             0.014512  0.026762                        0.012579   \n",
       "19             0.000399  0.000542                        0.003539   \n",
       "20             0.000022  0.001865                        0.000004   \n",
       "\n",
       "     appenzeller  australian_terrier       basenji    basset  \\\n",
       "0   7.997761e-03        4.293246e-03  4.821258e-03  0.009342   \n",
       "1   1.429782e-02        2.931678e-05  3.431739e-02  0.014508   \n",
       "2   3.952796e-05        1.223583e-03  1.371287e-07  0.000026   \n",
       "3   6.549921e-03        2.735183e-03  5.678755e-02  0.001180   \n",
       "4   9.496404e-05        9.247853e-05  1.696455e-07  0.000312   \n",
       "5   5.988509e-03        2.341162e-05  1.271904e-02  0.015437   \n",
       "6   9.863685e-02        7.200327e-07  4.649433e-03  0.034677   \n",
       "7   3.330973e-04        1.560937e-02  3.172185e-04  0.000124   \n",
       "8   2.642561e-04        4.624598e-04  1.848259e-06  0.000988   \n",
       "9   9.637496e-03        7.541211e-07  1.616295e-02  0.020645   \n",
       "10  1.966932e-04        7.953356e-03  1.787785e-04  0.000496   \n",
       "11  4.438528e-03        1.311200e-07  2.277971e-02  0.010233   \n",
       "12  9.317582e-03        2.288884e-04  1.817758e-03  0.022161   \n",
       "13  1.848778e-02        1.448244e-04  2.118008e-02  0.025932   \n",
       "14  1.614716e-02        1.798368e-05  2.839987e-02  0.026575   \n",
       "15  1.641616e-02        8.848020e-06  9.150978e-03  0.032366   \n",
       "16  4.626315e-07        4.807195e-05  6.311876e-06  0.000120   \n",
       "17  2.741991e-02        2.933388e-06  3.477264e-02  0.032344   \n",
       "18  1.954159e-03        1.109531e-03  8.891254e-03  0.003903   \n",
       "19  1.519336e-02        1.394305e-04  6.569310e-04  0.011730   \n",
       "20  1.639099e-07        1.866699e-04  1.337407e-09  0.000049   \n",
       "\n",
       "          ...          toy_poodle   toy_terrier        vizsla  walker_hound  \\\n",
       "0         ...            0.002738  3.733022e-03  9.822696e-03  2.508722e-03   \n",
       "1         ...            0.000015  2.943945e-02  1.640671e-02  1.638699e-02   \n",
       "2         ...            0.025404  1.410393e-04  4.843663e-07  5.266557e-15   \n",
       "3         ...            0.000005  4.220213e-02  5.620310e-05  7.477730e-05   \n",
       "4         ...            0.011698  2.265531e-04  3.700886e-06  6.313635e-12   \n",
       "5         ...            0.000212  1.074401e-03  4.326552e-02  1.679385e-02   \n",
       "6         ...            0.000005  1.663580e-02  8.847610e-05  3.564705e-03   \n",
       "7         ...            0.016011  1.055968e-03  5.933307e-04  2.963574e-07   \n",
       "8         ...            0.014121  5.202889e-04  2.934717e-05  3.126022e-09   \n",
       "9         ...            0.000011  3.296572e-03  3.807002e-02  2.921159e-02   \n",
       "10        ...            0.019448  3.693861e-04  1.533608e-03  6.215695e-07   \n",
       "11        ...            0.000006  1.244790e-03  4.381808e-02  1.701756e-02   \n",
       "12        ...            0.001448  1.526182e-03  1.097768e-02  5.616920e-03   \n",
       "13        ...            0.000801  1.572453e-02  1.754687e-02  1.817414e-02   \n",
       "14        ...            0.000226  1.290696e-02  2.299764e-02  2.403040e-02   \n",
       "15        ...            0.000311  2.916747e-03  2.206880e-02  2.449260e-02   \n",
       "16        ...            0.020229  4.429776e-08  1.953201e-03  5.970971e-07   \n",
       "17        ...            0.000100  3.283910e-02  9.710406e-03  2.691901e-02   \n",
       "18        ...            0.008748  5.504606e-04  2.367129e-02  1.872352e-03   \n",
       "19        ...            0.003435  5.813285e-03  3.976177e-04  3.323524e-04   \n",
       "20        ...            0.032164  1.476515e-06  6.700903e-07  1.464823e-13   \n",
       "\n",
       "      weimaraner  welsh_springer_spaniel  west_highland_white_terrier  \\\n",
       "0   6.091225e-03                0.009322                 1.757284e-03   \n",
       "1   1.126600e-02                0.000388                 1.912240e-06   \n",
       "2   1.066823e-08                0.000569                 1.352255e-02   \n",
       "3   1.493562e-05                0.000082                 4.612583e-04   \n",
       "4   9.797548e-07                0.006858                 2.832103e-03   \n",
       "5   3.652578e-02                0.001177                 2.180068e-06   \n",
       "6   1.160738e-04                0.057227                 7.832055e-06   \n",
       "7   8.284627e-05                0.000292                 8.990199e-03   \n",
       "8   1.559910e-05                0.010093                 5.771452e-03   \n",
       "9   3.844613e-02                0.000785                 5.946529e-08   \n",
       "10  3.683519e-04                0.000370                 4.893063e-03   \n",
       "11  2.918422e-02                0.000056                 4.553374e-09   \n",
       "12  1.279299e-02                0.045393                 2.750939e-04   \n",
       "13  2.289093e-02                0.012304                 1.711656e-04   \n",
       "14  2.755640e-02                0.003650                 1.050699e-05   \n",
       "15  3.682960e-02                0.032054                 2.402682e-05   \n",
       "16  7.273422e-04                0.000011                 2.714454e-05   \n",
       "17  1.753996e-02                0.006946                 8.038262e-06   \n",
       "18  1.130670e-02                0.000464                 3.038915e-04   \n",
       "19  6.206629e-04                0.046134                 1.564025e-03   \n",
       "20  7.781105e-07                0.000350                 1.204357e-03   \n",
       "\n",
       "     whippet  wire-haired_fox_terrier  yorkshire_terrier  \n",
       "0   0.008865                 0.011454       6.989223e-03  \n",
       "1   0.026700                 0.000794       4.937038e-06  \n",
       "2   0.000007                 0.005035       4.440775e-03  \n",
       "3   0.001162                 0.007072       1.800847e-04  \n",
       "4   0.000035                 0.003735       1.196462e-03  \n",
       "5   0.039987                 0.001064       1.683983e-05  \n",
       "6   0.001436                 0.002120       1.264341e-05  \n",
       "7   0.000986                 0.011440       1.261263e-02  \n",
       "8   0.000164                 0.005560       2.824786e-03  \n",
       "9   0.039363                 0.000238       5.109840e-07  \n",
       "10  0.002242                 0.009323       7.054249e-03  \n",
       "11  0.051081                 0.000082       2.599339e-08  \n",
       "12  0.010761                 0.008794       1.880500e-03  \n",
       "13  0.028274                 0.003315       2.269947e-04  \n",
       "14  0.037192                 0.001133       1.322103e-05  \n",
       "15  0.027020                 0.002629       1.000467e-04  \n",
       "16  0.002733                 0.002474       9.099605e-05  \n",
       "17  0.025119                 0.000865       3.953107e-06  \n",
       "18  0.025274                 0.004666       6.529735e-04  \n",
       "19  0.001812                 0.005435       1.575902e-03  \n",
       "20  0.000014                 0.004800       1.080963e-03  \n",
       "\n",
       "[21 rows x 121 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['id'] = df_sub.names.apply(lambda x: x.split('.jpg')[0])\n",
    "cols = ['id'] + class_names\n",
    "df_sub[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'affenpinscher',\n",
       " 'afghan_hound',\n",
       " 'african_hunting_dog',\n",
       " 'airedale',\n",
       " 'american_staffordshire_terrier',\n",
       " 'appenzeller',\n",
       " 'australian_terrier',\n",
       " 'basenji',\n",
       " 'basset',\n",
       " 'beagle',\n",
       " 'bedlington_terrier',\n",
       " 'bernese_mountain_dog',\n",
       " 'black-and-tan_coonhound',\n",
       " 'blenheim_spaniel',\n",
       " 'bloodhound',\n",
       " 'bluetick',\n",
       " 'border_collie',\n",
       " 'border_terrier',\n",
       " 'borzoi',\n",
       " 'boston_bull',\n",
       " 'bouvier_des_flandres',\n",
       " 'boxer',\n",
       " 'brabancon_griffon',\n",
       " 'briard',\n",
       " 'brittany_spaniel',\n",
       " 'bull_mastiff',\n",
       " 'cairn',\n",
       " 'cardigan',\n",
       " 'chesapeake_bay_retriever',\n",
       " 'chihuahua',\n",
       " 'chow',\n",
       " 'clumber',\n",
       " 'cocker_spaniel',\n",
       " 'collie',\n",
       " 'curly-coated_retriever',\n",
       " 'dandie_dinmont',\n",
       " 'dhole',\n",
       " 'dingo',\n",
       " 'doberman',\n",
       " 'english_foxhound',\n",
       " 'english_setter',\n",
       " 'english_springer',\n",
       " 'entlebucher',\n",
       " 'eskimo_dog',\n",
       " 'flat-coated_retriever',\n",
       " 'french_bulldog',\n",
       " 'german_shepherd',\n",
       " 'german_short-haired_pointer',\n",
       " 'giant_schnauzer',\n",
       " 'golden_retriever',\n",
       " 'gordon_setter',\n",
       " 'great_dane',\n",
       " 'great_pyrenees',\n",
       " 'greater_swiss_mountain_dog',\n",
       " 'groenendael',\n",
       " 'ibizan_hound',\n",
       " 'irish_setter',\n",
       " 'irish_terrier',\n",
       " 'irish_water_spaniel',\n",
       " 'irish_wolfhound',\n",
       " 'italian_greyhound',\n",
       " 'japanese_spaniel',\n",
       " 'keeshond',\n",
       " 'kelpie',\n",
       " 'kerry_blue_terrier',\n",
       " 'komondor',\n",
       " 'kuvasz',\n",
       " 'labrador_retriever',\n",
       " 'lakeland_terrier',\n",
       " 'leonberg',\n",
       " 'lhasa',\n",
       " 'malamute',\n",
       " 'malinois',\n",
       " 'maltese_dog',\n",
       " 'mexican_hairless',\n",
       " 'miniature_pinscher',\n",
       " 'miniature_poodle',\n",
       " 'miniature_schnauzer',\n",
       " 'newfoundland',\n",
       " 'norfolk_terrier',\n",
       " 'norwegian_elkhound',\n",
       " 'norwich_terrier',\n",
       " 'old_english_sheepdog',\n",
       " 'otterhound',\n",
       " 'papillon',\n",
       " 'pekinese',\n",
       " 'pembroke',\n",
       " 'pomeranian',\n",
       " 'pug',\n",
       " 'redbone',\n",
       " 'rhodesian_ridgeback',\n",
       " 'rottweiler',\n",
       " 'saint_bernard',\n",
       " 'saluki',\n",
       " 'samoyed',\n",
       " 'schipperke',\n",
       " 'scotch_terrier',\n",
       " 'scottish_deerhound',\n",
       " 'sealyham_terrier',\n",
       " 'shetland_sheepdog',\n",
       " 'shih-tzu',\n",
       " 'siberian_husky',\n",
       " 'silky_terrier',\n",
       " 'soft-coated_wheaten_terrier',\n",
       " 'staffordshire_bullterrier',\n",
       " 'standard_poodle',\n",
       " 'standard_schnauzer',\n",
       " 'sussex_spaniel',\n",
       " 'tibetan_mastiff',\n",
       " 'tibetan_terrier',\n",
       " 'toy_poodle',\n",
       " 'toy_terrier',\n",
       " 'vizsla',\n",
       " 'walker_hound',\n",
       " 'weimaraner',\n",
       " 'welsh_springer_spaniel',\n",
       " 'west_highland_white_terrier',\n",
       " 'whippet',\n",
       " 'wire-haired_fox_terrier',\n",
       " 'yorkshire_terrier']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affenpinscher</th>\n",
       "      <th>afghan_hound</th>\n",
       "      <th>african_hunting_dog</th>\n",
       "      <th>airedale</th>\n",
       "      <th>american_staffordshire_terrier</th>\n",
       "      <th>appenzeller</th>\n",
       "      <th>australian_terrier</th>\n",
       "      <th>basenji</th>\n",
       "      <th>basset</th>\n",
       "      <th>beagle</th>\n",
       "      <th>...</th>\n",
       "      <th>vizsla</th>\n",
       "      <th>walker_hound</th>\n",
       "      <th>weimaraner</th>\n",
       "      <th>welsh_springer_spaniel</th>\n",
       "      <th>west_highland_white_terrier</th>\n",
       "      <th>whippet</th>\n",
       "      <th>wire-haired_fox_terrier</th>\n",
       "      <th>yorkshire_terrier</th>\n",
       "      <th>names</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.022921</td>\n",
       "      <td>0.020423</td>\n",
       "      <td>0.024829</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>4.821258e-03</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>...</td>\n",
       "      <td>9.822696e-03</td>\n",
       "      <td>2.508722e-03</td>\n",
       "      <td>6.091225e-03</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.006989</td>\n",
       "      <td>ffb3a78e4a162c173219194687eb6054.jpg</td>\n",
       "      <td>ffb3a78e4a162c173219194687eb6054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.028737</td>\n",
       "      <td>0.014298</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>3.431739e-02</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.640671e-02</td>\n",
       "      <td>1.638699e-02</td>\n",
       "      <td>1.126600e-02</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>ffb55dbaa32939c109ef42df0668e077.jpg</td>\n",
       "      <td>ffb55dbaa32939c109ef42df0668e077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>1.371287e-07</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>4.843663e-07</td>\n",
       "      <td>5.266557e-15</td>\n",
       "      <td>1.066823e-08</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.013523</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>ffb68ded4a2247b3c011840ece0a605c.jpg</td>\n",
       "      <td>ffb68ded4a2247b3c011840ece0a605c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.032647</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>5.678755e-02</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>...</td>\n",
       "      <td>5.620310e-05</td>\n",
       "      <td>7.477730e-05</td>\n",
       "      <td>1.493562e-05</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>ffb8bceeac5b3f587f67391ad346d454.jpg</td>\n",
       "      <td>ffb8bceeac5b3f587f67391ad346d454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.022012</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>1.696455e-07</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>...</td>\n",
       "      <td>3.700886e-06</td>\n",
       "      <td>6.313635e-12</td>\n",
       "      <td>9.797548e-07</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>ffbb6663b38e903dbd1efa5dce2d0bbb.jpg</td>\n",
       "      <td>ffbb6663b38e903dbd1efa5dce2d0bbb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   affenpinscher  afghan_hound  african_hunting_dog  airedale  \\\n",
       "0       0.004964      0.022921             0.020423  0.024829   \n",
       "1       0.000004      0.000013             0.011611  0.001259   \n",
       "2       0.000177      0.011156             0.000057  0.000465   \n",
       "3       0.000074      0.000016             0.032647  0.000936   \n",
       "4       0.000007      0.022012             0.000024  0.000182   \n",
       "\n",
       "   american_staffordshire_terrier  appenzeller  australian_terrier  \\\n",
       "0                        0.007781     0.007998            0.004293   \n",
       "1                        0.028737     0.014298            0.000029   \n",
       "2                        0.000027     0.000040            0.001224   \n",
       "3                        0.004391     0.006550            0.002735   \n",
       "4                        0.000104     0.000095            0.000092   \n",
       "\n",
       "        basenji    basset    beagle                ...                 \\\n",
       "0  4.821258e-03  0.009342  0.002844                ...                  \n",
       "1  3.431739e-02  0.014508  0.016231                ...                  \n",
       "2  1.371287e-07  0.000026  0.000005                ...                  \n",
       "3  5.678755e-02  0.001180  0.000239                ...                  \n",
       "4  1.696455e-07  0.000312  0.000086                ...                  \n",
       "\n",
       "         vizsla  walker_hound    weimaraner  welsh_springer_spaniel  \\\n",
       "0  9.822696e-03  2.508722e-03  6.091225e-03                0.009322   \n",
       "1  1.640671e-02  1.638699e-02  1.126600e-02                0.000388   \n",
       "2  4.843663e-07  5.266557e-15  1.066823e-08                0.000569   \n",
       "3  5.620310e-05  7.477730e-05  1.493562e-05                0.000082   \n",
       "4  3.700886e-06  6.313635e-12  9.797548e-07                0.006858   \n",
       "\n",
       "   west_highland_white_terrier   whippet  wire-haired_fox_terrier  \\\n",
       "0                     0.001757  0.008865                 0.011454   \n",
       "1                     0.000002  0.026700                 0.000794   \n",
       "2                     0.013523  0.000007                 0.005035   \n",
       "3                     0.000461  0.001162                 0.007072   \n",
       "4                     0.002832  0.000035                 0.003735   \n",
       "\n",
       "   yorkshire_terrier                                 names  \\\n",
       "0           0.006989  ffb3a78e4a162c173219194687eb6054.jpg   \n",
       "1           0.000005  ffb55dbaa32939c109ef42df0668e077.jpg   \n",
       "2           0.004441  ffb68ded4a2247b3c011840ece0a605c.jpg   \n",
       "3           0.000180  ffb8bceeac5b3f587f67391ad346d454.jpg   \n",
       "4           0.001196  ffbb6663b38e903dbd1efa5dce2d0bbb.jpg   \n",
       "\n",
       "                                 id  \n",
       "0  ffb3a78e4a162c173219194687eb6054  \n",
       "1  ffb55dbaa32939c109ef42df0668e077  \n",
       "2  ffb68ded4a2247b3c011840ece0a605c  \n",
       "3  ffb8bceeac5b3f587f67391ad346d454  \n",
       "4  ffbb6663b38e903dbd1efa5dce2d0bbb  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.847685e-08</td>\n",
       "      <td>1.293495e-07</td>\n",
       "      <td>7.142829e-03</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>8.609867e-03</td>\n",
       "      <td>1.189664e-02</td>\n",
       "      <td>2.711941e-05</td>\n",
       "      <td>1.384494e-01</td>\n",
       "      <td>3.221923e-03</td>\n",
       "      <td>3.892942e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.669332e-08</td>\n",
       "      <td>1.027783e-01</td>\n",
       "      <td>4.033699e-05</td>\n",
       "      <td>4.792983e-04</td>\n",
       "      <td>1.774221e-05</td>\n",
       "      <td>2.442142e-05</td>\n",
       "      <td>3.153348e-06</td>\n",
       "      <td>1.543514e-03</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>8.141250e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.270168e-06</td>\n",
       "      <td>1.042112e-05</td>\n",
       "      <td>9.965837e-03</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>3.265768e-02</td>\n",
       "      <td>1.740819e-02</td>\n",
       "      <td>4.520308e-05</td>\n",
       "      <td>5.746185e-02</td>\n",
       "      <td>1.581398e-02</td>\n",
       "      <td>1.357656e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.129487e-05</td>\n",
       "      <td>4.592009e-02</td>\n",
       "      <td>8.247143e-03</td>\n",
       "      <td>1.302265e-02</td>\n",
       "      <td>5.583113e-03</td>\n",
       "      <td>4.345822e-04</td>\n",
       "      <td>7.502006e-06</td>\n",
       "      <td>2.364263e-02</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>5.605015e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.696525e-03</td>\n",
       "      <td>2.290840e-02</td>\n",
       "      <td>1.906859e-04</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>1.359560e-06</td>\n",
       "      <td>3.734564e-06</td>\n",
       "      <td>1.914438e-02</td>\n",
       "      <td>1.455506e-08</td>\n",
       "      <td>5.899144e-06</td>\n",
       "      <td>5.602906e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.024133e-02</td>\n",
       "      <td>1.517217e-04</td>\n",
       "      <td>2.456583e-08</td>\n",
       "      <td>1.728060e-15</td>\n",
       "      <td>2.117221e-09</td>\n",
       "      <td>2.862016e-04</td>\n",
       "      <td>4.158496e-02</td>\n",
       "      <td>9.256034e-07</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>2.847234e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.672391e-02</td>\n",
       "      <td>8.788795e-04</td>\n",
       "      <td>3.580221e-04</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>1.576711e-09</td>\n",
       "      <td>8.381488e-08</td>\n",
       "      <td>1.848059e-01</td>\n",
       "      <td>2.877760e-09</td>\n",
       "      <td>8.251907e-10</td>\n",
       "      <td>7.075921e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>7.077620e-05</td>\n",
       "      <td>6.268935e-05</td>\n",
       "      <td>1.492606e-13</td>\n",
       "      <td>1.874724e-21</td>\n",
       "      <td>1.818215e-15</td>\n",
       "      <td>2.585664e-07</td>\n",
       "      <td>4.931156e-02</td>\n",
       "      <td>2.472243e-10</td>\n",
       "      <td>0.027591</td>\n",
       "      <td>1.039180e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.764122e-04</td>\n",
       "      <td>9.196560e-04</td>\n",
       "      <td>9.215328e-03</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>1.899653e-02</td>\n",
       "      <td>2.100000e-03</td>\n",
       "      <td>1.530654e-04</td>\n",
       "      <td>1.171448e-02</td>\n",
       "      <td>5.772892e-03</td>\n",
       "      <td>8.138245e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.809097e-03</td>\n",
       "      <td>3.204215e-04</td>\n",
       "      <td>4.150610e-02</td>\n",
       "      <td>3.392897e-03</td>\n",
       "      <td>2.128355e-02</td>\n",
       "      <td>3.612888e-04</td>\n",
       "      <td>3.555209e-05</td>\n",
       "      <td>4.320706e-02</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>9.242539e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.244670e-08</td>\n",
       "      <td>1.574225e-02</td>\n",
       "      <td>9.257778e-07</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.706415e-04</td>\n",
       "      <td>1.476192e-06</td>\n",
       "      <td>3.161075e-08</td>\n",
       "      <td>6.366911e-09</td>\n",
       "      <td>5.563954e-04</td>\n",
       "      <td>3.961199e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367521e-03</td>\n",
       "      <td>1.461070e-07</td>\n",
       "      <td>7.066033e-05</td>\n",
       "      <td>3.124876e-10</td>\n",
       "      <td>5.857433e-05</td>\n",
       "      <td>6.009514e-03</td>\n",
       "      <td>1.837190e-06</td>\n",
       "      <td>1.467160e-04</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>5.982155e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.884103e-08</td>\n",
       "      <td>6.259249e-06</td>\n",
       "      <td>1.796884e-03</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>3.264154e-02</td>\n",
       "      <td>1.829353e-02</td>\n",
       "      <td>2.618490e-07</td>\n",
       "      <td>1.807967e-02</td>\n",
       "      <td>2.769084e-02</td>\n",
       "      <td>5.127278e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.616085e-06</td>\n",
       "      <td>1.214712e-02</td>\n",
       "      <td>2.653526e-02</td>\n",
       "      <td>3.870709e-02</td>\n",
       "      <td>3.361572e-02</td>\n",
       "      <td>1.510170e-03</td>\n",
       "      <td>3.460343e-08</td>\n",
       "      <td>3.371302e-02</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>2.827911e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.541406e-02</td>\n",
       "      <td>6.892887e-03</td>\n",
       "      <td>1.867199e-02</td>\n",
       "      <td>0.036760</td>\n",
       "      <td>4.779892e-03</td>\n",
       "      <td>8.756145e-04</td>\n",
       "      <td>4.974525e-03</td>\n",
       "      <td>3.414055e-03</td>\n",
       "      <td>4.038532e-04</td>\n",
       "      <td>8.314917e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193774e-02</td>\n",
       "      <td>5.591228e-04</td>\n",
       "      <td>4.800574e-03</td>\n",
       "      <td>1.041047e-04</td>\n",
       "      <td>1.213294e-03</td>\n",
       "      <td>1.456854e-04</td>\n",
       "      <td>1.554905e-03</td>\n",
       "      <td>5.186857e-03</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>3.409334e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.585345e-04</td>\n",
       "      <td>4.113255e-04</td>\n",
       "      <td>2.428345e-02</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>1.841808e-02</td>\n",
       "      <td>1.300575e-02</td>\n",
       "      <td>1.604122e-03</td>\n",
       "      <td>4.083299e-02</td>\n",
       "      <td>1.048866e-02</td>\n",
       "      <td>5.435311e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.816764e-04</td>\n",
       "      <td>2.838984e-02</td>\n",
       "      <td>4.783686e-03</td>\n",
       "      <td>4.692473e-03</td>\n",
       "      <td>3.138494e-03</td>\n",
       "      <td>1.272224e-03</td>\n",
       "      <td>7.073253e-04</td>\n",
       "      <td>1.477244e-02</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>3.944759e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.624531e-03</td>\n",
       "      <td>6.535420e-02</td>\n",
       "      <td>8.081776e-04</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.562931e-04</td>\n",
       "      <td>1.632125e-04</td>\n",
       "      <td>3.609805e-03</td>\n",
       "      <td>3.097961e-06</td>\n",
       "      <td>1.176712e-03</td>\n",
       "      <td>1.401196e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.295369e-02</td>\n",
       "      <td>4.185833e-04</td>\n",
       "      <td>5.100990e-05</td>\n",
       "      <td>4.777508e-08</td>\n",
       "      <td>3.996796e-05</td>\n",
       "      <td>7.475850e-03</td>\n",
       "      <td>6.999522e-03</td>\n",
       "      <td>2.149412e-04</td>\n",
       "      <td>0.015026</td>\n",
       "      <td>1.122399e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.130672e-02</td>\n",
       "      <td>1.517699e-02</td>\n",
       "      <td>3.436250e-03</td>\n",
       "      <td>0.029707</td>\n",
       "      <td>6.358857e-05</td>\n",
       "      <td>8.632306e-06</td>\n",
       "      <td>1.378576e-02</td>\n",
       "      <td>2.881864e-06</td>\n",
       "      <td>2.303343e-05</td>\n",
       "      <td>1.117404e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.783594e-02</td>\n",
       "      <td>1.106688e-04</td>\n",
       "      <td>1.842152e-05</td>\n",
       "      <td>7.565489e-11</td>\n",
       "      <td>2.543299e-06</td>\n",
       "      <td>6.975654e-05</td>\n",
       "      <td>8.775717e-03</td>\n",
       "      <td>9.978224e-05</td>\n",
       "      <td>0.012134</td>\n",
       "      <td>1.218568e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.265724e-02</td>\n",
       "      <td>1.491980e-02</td>\n",
       "      <td>5.488219e-04</td>\n",
       "      <td>0.012839</td>\n",
       "      <td>1.987189e-07</td>\n",
       "      <td>1.375711e-07</td>\n",
       "      <td>5.031993e-02</td>\n",
       "      <td>5.434790e-09</td>\n",
       "      <td>2.883121e-07</td>\n",
       "      <td>2.452514e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.491571e-02</td>\n",
       "      <td>5.061981e-05</td>\n",
       "      <td>4.169224e-09</td>\n",
       "      <td>5.825544e-16</td>\n",
       "      <td>6.430941e-10</td>\n",
       "      <td>8.092158e-06</td>\n",
       "      <td>2.736496e-02</td>\n",
       "      <td>2.786564e-07</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>4.310506e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.894130e-02</td>\n",
       "      <td>4.969303e-03</td>\n",
       "      <td>2.189895e-06</td>\n",
       "      <td>0.005932</td>\n",
       "      <td>3.925415e-11</td>\n",
       "      <td>7.834396e-14</td>\n",
       "      <td>1.604052e-03</td>\n",
       "      <td>3.717592e-15</td>\n",
       "      <td>1.876314e-10</td>\n",
       "      <td>1.221595e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>7.294199e-02</td>\n",
       "      <td>1.713316e-09</td>\n",
       "      <td>4.519214e-13</td>\n",
       "      <td>7.017496e-26</td>\n",
       "      <td>7.223292e-14</td>\n",
       "      <td>3.471981e-09</td>\n",
       "      <td>1.937811e-03</td>\n",
       "      <td>8.672912e-10</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>2.055801e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.508847e-10</td>\n",
       "      <td>1.494057e-05</td>\n",
       "      <td>1.983965e-04</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>3.815953e-02</td>\n",
       "      <td>3.473254e-02</td>\n",
       "      <td>7.998524e-09</td>\n",
       "      <td>1.729366e-02</td>\n",
       "      <td>4.485394e-02</td>\n",
       "      <td>9.464947e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.183934e-06</td>\n",
       "      <td>1.483889e-02</td>\n",
       "      <td>1.146830e-02</td>\n",
       "      <td>5.389154e-02</td>\n",
       "      <td>2.680846e-02</td>\n",
       "      <td>8.270864e-03</td>\n",
       "      <td>1.724453e-08</td>\n",
       "      <td>2.398204e-02</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>8.777279e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.016975e-02</td>\n",
       "      <td>3.972952e-03</td>\n",
       "      <td>5.633199e-04</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>3.534224e-07</td>\n",
       "      <td>5.580213e-08</td>\n",
       "      <td>1.720330e-02</td>\n",
       "      <td>1.082876e-08</td>\n",
       "      <td>4.096291e-08</td>\n",
       "      <td>4.146534e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>4.536505e-02</td>\n",
       "      <td>1.543339e-05</td>\n",
       "      <td>3.474765e-09</td>\n",
       "      <td>6.207950e-19</td>\n",
       "      <td>4.997448e-11</td>\n",
       "      <td>9.674188e-07</td>\n",
       "      <td>2.125577e-02</td>\n",
       "      <td>3.652677e-07</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>1.685406e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.626724e-07</td>\n",
       "      <td>5.824601e-04</td>\n",
       "      <td>2.217623e-03</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>2.109653e-02</td>\n",
       "      <td>6.653231e-02</td>\n",
       "      <td>1.258381e-05</td>\n",
       "      <td>2.918500e-02</td>\n",
       "      <td>4.585717e-02</td>\n",
       "      <td>2.490742e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.474928e-05</td>\n",
       "      <td>3.630654e-02</td>\n",
       "      <td>2.325977e-03</td>\n",
       "      <td>1.359013e-02</td>\n",
       "      <td>2.137003e-03</td>\n",
       "      <td>1.972542e-02</td>\n",
       "      <td>1.712164e-05</td>\n",
       "      <td>1.276511e-02</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>3.717183e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.628311e-03</td>\n",
       "      <td>2.494914e-02</td>\n",
       "      <td>6.769272e-03</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>5.786333e-03</td>\n",
       "      <td>1.818810e-02</td>\n",
       "      <td>3.299213e-03</td>\n",
       "      <td>6.422191e-03</td>\n",
       "      <td>1.468619e-02</td>\n",
       "      <td>7.368831e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.970528e-03</td>\n",
       "      <td>8.698376e-03</td>\n",
       "      <td>2.368001e-03</td>\n",
       "      <td>3.506006e-03</td>\n",
       "      <td>2.182393e-03</td>\n",
       "      <td>2.532663e-02</td>\n",
       "      <td>5.368031e-03</td>\n",
       "      <td>6.167508e-03</td>\n",
       "      <td>0.011716</td>\n",
       "      <td>7.172239e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.852944e-08</td>\n",
       "      <td>6.195425e-08</td>\n",
       "      <td>8.292942e-03</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>2.574259e-02</td>\n",
       "      <td>9.997768e-03</td>\n",
       "      <td>4.477190e-06</td>\n",
       "      <td>7.822428e-02</td>\n",
       "      <td>6.121203e-03</td>\n",
       "      <td>4.460340e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.673960e-07</td>\n",
       "      <td>6.454495e-02</td>\n",
       "      <td>3.061159e-03</td>\n",
       "      <td>6.553983e-03</td>\n",
       "      <td>1.117819e-03</td>\n",
       "      <td>1.116957e-05</td>\n",
       "      <td>7.894314e-08</td>\n",
       "      <td>1.246399e-02</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>8.519061e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.856229e-06</td>\n",
       "      <td>1.394843e-02</td>\n",
       "      <td>7.889632e-07</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>2.887707e-07</td>\n",
       "      <td>3.714132e-07</td>\n",
       "      <td>1.163163e-04</td>\n",
       "      <td>2.656857e-11</td>\n",
       "      <td>2.664425e-06</td>\n",
       "      <td>1.875904e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.615376e-02</td>\n",
       "      <td>7.306344e-06</td>\n",
       "      <td>1.489474e-09</td>\n",
       "      <td>6.090876e-20</td>\n",
       "      <td>5.140298e-11</td>\n",
       "      <td>3.767794e-04</td>\n",
       "      <td>6.026766e-03</td>\n",
       "      <td>8.334968e-08</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>1.356150e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.643993e-03</td>\n",
       "      <td>2.019568e-02</td>\n",
       "      <td>5.818277e-03</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>2.926486e-03</td>\n",
       "      <td>2.991601e-03</td>\n",
       "      <td>7.148639e-03</td>\n",
       "      <td>6.616854e-04</td>\n",
       "      <td>3.892438e-03</td>\n",
       "      <td>1.979758e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.575539e-02</td>\n",
       "      <td>3.874753e-03</td>\n",
       "      <td>1.382905e-03</td>\n",
       "      <td>1.414379e-05</td>\n",
       "      <td>7.967677e-04</td>\n",
       "      <td>8.758931e-03</td>\n",
       "      <td>1.229896e-02</td>\n",
       "      <td>3.055140e-03</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>9.727823e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.842709e-04</td>\n",
       "      <td>1.249722e-01</td>\n",
       "      <td>1.137300e-03</td>\n",
       "      <td>0.023770</td>\n",
       "      <td>3.181426e-05</td>\n",
       "      <td>4.308400e-05</td>\n",
       "      <td>3.444468e-04</td>\n",
       "      <td>4.831695e-07</td>\n",
       "      <td>1.706209e-04</td>\n",
       "      <td>2.113400e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.577987e-05</td>\n",
       "      <td>1.571536e-05</td>\n",
       "      <td>6.242876e-05</td>\n",
       "      <td>4.085453e-07</td>\n",
       "      <td>2.345667e-05</td>\n",
       "      <td>8.929261e-04</td>\n",
       "      <td>1.045647e-05</td>\n",
       "      <td>2.898557e-05</td>\n",
       "      <td>0.015012</td>\n",
       "      <td>4.284901e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.669377e-03</td>\n",
       "      <td>3.084786e-03</td>\n",
       "      <td>4.040345e-02</td>\n",
       "      <td>0.016375</td>\n",
       "      <td>4.266542e-03</td>\n",
       "      <td>3.189070e-03</td>\n",
       "      <td>1.902385e-02</td>\n",
       "      <td>9.701132e-03</td>\n",
       "      <td>6.216490e-04</td>\n",
       "      <td>9.970977e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.649579e-03</td>\n",
       "      <td>9.926465e-03</td>\n",
       "      <td>6.573763e-04</td>\n",
       "      <td>1.077616e-04</td>\n",
       "      <td>2.616834e-04</td>\n",
       "      <td>7.161819e-04</td>\n",
       "      <td>9.239758e-03</td>\n",
       "      <td>2.383423e-03</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>9.128398e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.629297e-05</td>\n",
       "      <td>1.907122e-02</td>\n",
       "      <td>3.920791e-05</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>1.598996e-05</td>\n",
       "      <td>3.770192e-04</td>\n",
       "      <td>6.547365e-04</td>\n",
       "      <td>2.551767e-07</td>\n",
       "      <td>1.048138e-04</td>\n",
       "      <td>9.854643e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.488286e-03</td>\n",
       "      <td>5.717560e-04</td>\n",
       "      <td>1.337887e-07</td>\n",
       "      <td>9.381543e-14</td>\n",
       "      <td>1.032817e-08</td>\n",
       "      <td>5.589440e-03</td>\n",
       "      <td>8.669947e-03</td>\n",
       "      <td>3.692293e-06</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>4.959813e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.695524e-07</td>\n",
       "      <td>3.703341e-02</td>\n",
       "      <td>3.170915e-05</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>4.513304e-04</td>\n",
       "      <td>9.041935e-03</td>\n",
       "      <td>6.164646e-06</td>\n",
       "      <td>1.819471e-05</td>\n",
       "      <td>6.597145e-03</td>\n",
       "      <td>2.438435e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.943557e-04</td>\n",
       "      <td>1.430075e-03</td>\n",
       "      <td>3.548071e-05</td>\n",
       "      <td>7.255850e-06</td>\n",
       "      <td>5.180105e-05</td>\n",
       "      <td>1.039390e-01</td>\n",
       "      <td>1.161292e-04</td>\n",
       "      <td>1.975549e-04</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>4.601831e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.732728e-03</td>\n",
       "      <td>1.523245e-02</td>\n",
       "      <td>1.818183e-02</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>6.918567e-03</td>\n",
       "      <td>1.319394e-02</td>\n",
       "      <td>9.678333e-03</td>\n",
       "      <td>1.006819e-02</td>\n",
       "      <td>1.065236e-02</td>\n",
       "      <td>3.856927e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.110014e-03</td>\n",
       "      <td>1.069146e-02</td>\n",
       "      <td>2.812773e-03</td>\n",
       "      <td>2.089535e-03</td>\n",
       "      <td>1.748035e-03</td>\n",
       "      <td>1.086584e-02</td>\n",
       "      <td>8.164150e-03</td>\n",
       "      <td>6.883197e-03</td>\n",
       "      <td>0.015710</td>\n",
       "      <td>9.414782e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.982642e-11</td>\n",
       "      <td>1.427160e-04</td>\n",
       "      <td>1.664549e-05</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.955649e-02</td>\n",
       "      <td>1.786852e-02</td>\n",
       "      <td>8.010175e-11</td>\n",
       "      <td>1.225565e-03</td>\n",
       "      <td>5.460930e-02</td>\n",
       "      <td>1.798984e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.151365e-07</td>\n",
       "      <td>1.340782e-04</td>\n",
       "      <td>1.480082e-02</td>\n",
       "      <td>7.944725e-02</td>\n",
       "      <td>5.876425e-02</td>\n",
       "      <td>3.984176e-02</td>\n",
       "      <td>2.206346e-10</td>\n",
       "      <td>1.617369e-02</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>3.826865e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.777247e-07</td>\n",
       "      <td>2.611252e-02</td>\n",
       "      <td>3.090981e-05</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>3.602404e-04</td>\n",
       "      <td>5.210192e-03</td>\n",
       "      <td>2.102832e-05</td>\n",
       "      <td>1.329612e-05</td>\n",
       "      <td>2.947020e-03</td>\n",
       "      <td>1.056750e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.632076e-03</td>\n",
       "      <td>1.847915e-03</td>\n",
       "      <td>1.308453e-05</td>\n",
       "      <td>1.737339e-07</td>\n",
       "      <td>1.352434e-05</td>\n",
       "      <td>4.636052e-02</td>\n",
       "      <td>6.124565e-04</td>\n",
       "      <td>1.263843e-04</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>7.322557e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.192295e-07</td>\n",
       "      <td>5.967904e-03</td>\n",
       "      <td>7.791497e-08</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4.966425e-08</td>\n",
       "      <td>4.389884e-09</td>\n",
       "      <td>5.778895e-06</td>\n",
       "      <td>4.084516e-13</td>\n",
       "      <td>2.817065e-07</td>\n",
       "      <td>2.313983e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.605191e-02</td>\n",
       "      <td>1.381661e-07</td>\n",
       "      <td>2.327060e-10</td>\n",
       "      <td>1.802867e-23</td>\n",
       "      <td>5.748613e-12</td>\n",
       "      <td>3.126083e-05</td>\n",
       "      <td>9.744840e-04</td>\n",
       "      <td>2.292595e-08</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>1.418546e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.413976e-03</td>\n",
       "      <td>1.136199e-02</td>\n",
       "      <td>9.175130e-03</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>1.225686e-02</td>\n",
       "      <td>5.203336e-03</td>\n",
       "      <td>1.110726e-03</td>\n",
       "      <td>8.945696e-03</td>\n",
       "      <td>1.043827e-02</td>\n",
       "      <td>9.701947e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.975502e-03</td>\n",
       "      <td>2.075382e-03</td>\n",
       "      <td>1.598854e-02</td>\n",
       "      <td>5.273805e-03</td>\n",
       "      <td>1.596730e-02</td>\n",
       "      <td>8.504610e-03</td>\n",
       "      <td>1.710547e-03</td>\n",
       "      <td>2.000252e-02</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>2.113938e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.849935e-04</td>\n",
       "      <td>1.512450e-03</td>\n",
       "      <td>2.377927e-02</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>1.848555e-02</td>\n",
       "      <td>1.238400e-02</td>\n",
       "      <td>1.620594e-03</td>\n",
       "      <td>2.272642e-02</td>\n",
       "      <td>1.394136e-02</td>\n",
       "      <td>1.045409e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>8.532277e-04</td>\n",
       "      <td>1.800040e-02</td>\n",
       "      <td>1.334621e-02</td>\n",
       "      <td>8.641127e-03</td>\n",
       "      <td>9.508755e-03</td>\n",
       "      <td>3.138882e-03</td>\n",
       "      <td>6.213931e-04</td>\n",
       "      <td>2.181064e-02</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>7.138547e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.025079e-08</td>\n",
       "      <td>2.130626e-02</td>\n",
       "      <td>1.885327e-05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>9.521344e-04</td>\n",
       "      <td>1.568278e-02</td>\n",
       "      <td>1.191238e-06</td>\n",
       "      <td>4.920278e-05</td>\n",
       "      <td>9.944577e-03</td>\n",
       "      <td>5.638435e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.088253e-04</td>\n",
       "      <td>1.673349e-03</td>\n",
       "      <td>5.416142e-05</td>\n",
       "      <td>5.935537e-05</td>\n",
       "      <td>1.084821e-04</td>\n",
       "      <td>1.156065e-01</td>\n",
       "      <td>3.891247e-05</td>\n",
       "      <td>3.292833e-04</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>1.472851e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.289803e-05</td>\n",
       "      <td>1.528972e-02</td>\n",
       "      <td>1.433081e-03</td>\n",
       "      <td>0.011315</td>\n",
       "      <td>3.676653e-03</td>\n",
       "      <td>6.795818e-04</td>\n",
       "      <td>3.239090e-06</td>\n",
       "      <td>1.064308e-04</td>\n",
       "      <td>8.504747e-03</td>\n",
       "      <td>7.801481e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.890236e-05</td>\n",
       "      <td>7.255061e-06</td>\n",
       "      <td>2.320304e-02</td>\n",
       "      <td>1.387838e-03</td>\n",
       "      <td>2.329695e-02</td>\n",
       "      <td>1.011588e-02</td>\n",
       "      <td>2.844163e-07</td>\n",
       "      <td>6.146124e-03</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>8.235952e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0             1             2         3             4    \\\n",
       "0   4.847685e-08  1.293495e-07  7.142829e-03  0.000033  8.609867e-03   \n",
       "1   1.270168e-06  1.042112e-05  9.965837e-03  0.000599  3.265768e-02   \n",
       "2   4.696525e-03  2.290840e-02  1.906859e-04  0.002687  1.359560e-06   \n",
       "3   1.672391e-02  8.788795e-04  3.580221e-04  0.001527  1.576711e-09   \n",
       "4   4.764122e-04  9.196560e-04  9.215328e-03  0.015434  1.899653e-02   \n",
       "5   4.244670e-08  1.574225e-02  9.257778e-07  0.000078  1.706415e-04   \n",
       "6   3.884103e-08  6.259249e-06  1.796884e-03  0.000253  3.264154e-02   \n",
       "7   1.541406e-02  6.892887e-03  1.867199e-02  0.036760  4.779892e-03   \n",
       "8   1.585345e-04  4.113255e-04  2.428345e-02  0.003841  1.841808e-02   \n",
       "9   1.624531e-03  6.535420e-02  8.081776e-04  0.006500  1.562931e-04   \n",
       "10  3.130672e-02  1.517699e-02  3.436250e-03  0.029707  6.358857e-05   \n",
       "11  3.265724e-02  1.491980e-02  5.488219e-04  0.012839  1.987189e-07   \n",
       "12  1.894130e-02  4.969303e-03  2.189895e-06  0.005932  3.925415e-11   \n",
       "13  2.508847e-10  1.494057e-05  1.983965e-04  0.000024  3.815953e-02   \n",
       "14  5.016975e-02  3.972952e-03  5.633199e-04  0.014335  3.534224e-07   \n",
       "15  6.626724e-07  5.824601e-04  2.217623e-03  0.000439  2.109653e-02   \n",
       "16  1.628311e-03  2.494914e-02  6.769272e-03  0.007519  5.786333e-03   \n",
       "17  3.852944e-08  6.195425e-08  8.292942e-03  0.000103  2.574259e-02   \n",
       "18  5.856229e-06  1.394843e-02  7.889632e-07  0.000035  2.887707e-07   \n",
       "19  3.643993e-03  2.019568e-02  5.818277e-03  0.009299  2.926486e-03   \n",
       "20  5.842709e-04  1.249722e-01  1.137300e-03  0.023770  3.181426e-05   \n",
       "21  9.669377e-03  3.084786e-03  4.040345e-02  0.016375  4.266542e-03   \n",
       "22  3.629297e-05  1.907122e-02  3.920791e-05  0.000170  1.598996e-05   \n",
       "23  4.695524e-07  3.703341e-02  3.170915e-05  0.000100  4.513304e-04   \n",
       "24  4.732728e-03  1.523245e-02  1.818183e-02  0.013723  6.918567e-03   \n",
       "25  6.982642e-11  1.427160e-04  1.664549e-05  0.000018  1.955649e-02   \n",
       "26  8.777247e-07  2.611252e-02  3.090981e-05  0.000082  3.602404e-04   \n",
       "27  6.192295e-07  5.967904e-03  7.791497e-08  0.000015  4.966425e-08   \n",
       "28  1.413976e-03  1.136199e-02  9.175130e-03  0.011936  1.225686e-02   \n",
       "29  5.849935e-04  1.512450e-03  2.377927e-02  0.008667  1.848555e-02   \n",
       "30  7.025079e-08  2.130626e-02  1.885327e-05  0.000042  9.521344e-04   \n",
       "31  4.289803e-05  1.528972e-02  1.433081e-03  0.011315  3.676653e-03   \n",
       "\n",
       "             5             6             7             8             9    \\\n",
       "0   1.189664e-02  2.711941e-05  1.384494e-01  3.221923e-03  3.892942e-04   \n",
       "1   1.740819e-02  4.520308e-05  5.746185e-02  1.581398e-02  1.357656e-02   \n",
       "2   3.734564e-06  1.914438e-02  1.455506e-08  5.899144e-06  5.602906e-07   \n",
       "3   8.381488e-08  1.848059e-01  2.877760e-09  8.251907e-10  7.075921e-12   \n",
       "4   2.100000e-03  1.530654e-04  1.171448e-02  5.772892e-03  8.138245e-03   \n",
       "5   1.476192e-06  3.161075e-08  6.366911e-09  5.563954e-04  3.961199e-04   \n",
       "6   1.829353e-02  2.618490e-07  1.807967e-02  2.769084e-02  5.127278e-02   \n",
       "7   8.756145e-04  4.974525e-03  3.414055e-03  4.038532e-04  8.314917e-04   \n",
       "8   1.300575e-02  1.604122e-03  4.083299e-02  1.048866e-02  5.435311e-03   \n",
       "9   1.632125e-04  3.609805e-03  3.097961e-06  1.176712e-03  1.401196e-04   \n",
       "10  8.632306e-06  1.378576e-02  2.881864e-06  2.303343e-05  1.117404e-05   \n",
       "11  1.375711e-07  5.031993e-02  5.434790e-09  2.883121e-07  2.452514e-08   \n",
       "12  7.834396e-14  1.604052e-03  3.717592e-15  1.876314e-10  1.221595e-11   \n",
       "13  3.473254e-02  7.998524e-09  1.729366e-02  4.485394e-02  9.464947e-02   \n",
       "14  5.580213e-08  1.720330e-02  1.082876e-08  4.096291e-08  4.146534e-08   \n",
       "15  6.653231e-02  1.258381e-05  2.918500e-02  4.585717e-02  2.490742e-02   \n",
       "16  1.818810e-02  3.299213e-03  6.422191e-03  1.468619e-02  7.368831e-03   \n",
       "17  9.997768e-03  4.477190e-06  7.822428e-02  6.121203e-03  4.460340e-03   \n",
       "18  3.714132e-07  1.163163e-04  2.656857e-11  2.664425e-06  1.875904e-07   \n",
       "19  2.991601e-03  7.148639e-03  6.616854e-04  3.892438e-03  1.979758e-03   \n",
       "20  4.308400e-05  3.444468e-04  4.831695e-07  1.706209e-04  2.113400e-07   \n",
       "21  3.189070e-03  1.902385e-02  9.701132e-03  6.216490e-04  9.970977e-04   \n",
       "22  3.770192e-04  6.547365e-04  2.551767e-07  1.048138e-04  9.854643e-06   \n",
       "23  9.041935e-03  6.164646e-06  1.819471e-05  6.597145e-03  2.438435e-03   \n",
       "24  1.319394e-02  9.678333e-03  1.006819e-02  1.065236e-02  3.856927e-03   \n",
       "25  1.786852e-02  8.010175e-11  1.225565e-03  5.460930e-02  1.798984e-01   \n",
       "26  5.210192e-03  2.102832e-05  1.329612e-05  2.947020e-03  1.056750e-03   \n",
       "27  4.389884e-09  5.778895e-06  4.084516e-13  2.817065e-07  2.313983e-08   \n",
       "28  5.203336e-03  1.110726e-03  8.945696e-03  1.043827e-02  9.701947e-03   \n",
       "29  1.238400e-02  1.620594e-03  2.272642e-02  1.394136e-02  1.045409e-02   \n",
       "30  1.568278e-02  1.191238e-06  4.920278e-05  9.944577e-03  5.638435e-03   \n",
       "31  6.795818e-04  3.239090e-06  1.064308e-04  8.504747e-03  7.801481e-04   \n",
       "\n",
       "        ...                110           111           112           113  \\\n",
       "0       ...       4.669332e-08  1.027783e-01  4.033699e-05  4.792983e-04   \n",
       "1       ...       2.129487e-05  4.592009e-02  8.247143e-03  1.302265e-02   \n",
       "2       ...       2.024133e-02  1.517217e-04  2.456583e-08  1.728060e-15   \n",
       "3       ...       7.077620e-05  6.268935e-05  1.492606e-13  1.874724e-21   \n",
       "4       ...       3.809097e-03  3.204215e-04  4.150610e-02  3.392897e-03   \n",
       "5       ...       1.367521e-03  1.461070e-07  7.066033e-05  3.124876e-10   \n",
       "6       ...       2.616085e-06  1.214712e-02  2.653526e-02  3.870709e-02   \n",
       "7       ...       1.193774e-02  5.591228e-04  4.800574e-03  1.041047e-04   \n",
       "8       ...       3.816764e-04  2.838984e-02  4.783686e-03  4.692473e-03   \n",
       "9       ...       1.295369e-02  4.185833e-04  5.100990e-05  4.777508e-08   \n",
       "10      ...       2.783594e-02  1.106688e-04  1.842152e-05  7.565489e-11   \n",
       "11      ...       1.491571e-02  5.061981e-05  4.169224e-09  5.825544e-16   \n",
       "12      ...       7.294199e-02  1.713316e-09  4.519214e-13  7.017496e-26   \n",
       "13      ...       1.183934e-06  1.483889e-02  1.146830e-02  5.389154e-02   \n",
       "14      ...       4.536505e-02  1.543339e-05  3.474765e-09  6.207950e-19   \n",
       "15      ...       1.474928e-05  3.630654e-02  2.325977e-03  1.359013e-02   \n",
       "16      ...       3.970528e-03  8.698376e-03  2.368001e-03  3.506006e-03   \n",
       "17      ...       1.673960e-07  6.454495e-02  3.061159e-03  6.553983e-03   \n",
       "18      ...       1.615376e-02  7.306344e-06  1.489474e-09  6.090876e-20   \n",
       "19      ...       1.575539e-02  3.874753e-03  1.382905e-03  1.414379e-05   \n",
       "20      ...       4.577987e-05  1.571536e-05  6.242876e-05  4.085453e-07   \n",
       "21      ...       1.649579e-03  9.926465e-03  6.573763e-04  1.077616e-04   \n",
       "22      ...       4.488286e-03  5.717560e-04  1.337887e-07  9.381543e-14   \n",
       "23      ...       3.943557e-04  1.430075e-03  3.548071e-05  7.255850e-06   \n",
       "24      ...       3.110014e-03  1.069146e-02  2.812773e-03  2.089535e-03   \n",
       "25      ...       2.151365e-07  1.340782e-04  1.480082e-02  7.944725e-02   \n",
       "26      ...       1.632076e-03  1.847915e-03  1.308453e-05  1.737339e-07   \n",
       "27      ...       3.605191e-02  1.381661e-07  2.327060e-10  1.802867e-23   \n",
       "28      ...       7.975502e-03  2.075382e-03  1.598854e-02  5.273805e-03   \n",
       "29      ...       8.532277e-04  1.800040e-02  1.334621e-02  8.641127e-03   \n",
       "30      ...       2.088253e-04  1.673349e-03  5.416142e-05  5.935537e-05   \n",
       "31      ...       3.890236e-05  7.255061e-06  2.320304e-02  1.387838e-03   \n",
       "\n",
       "             114           115           116           117       118  \\\n",
       "0   1.774221e-05  2.442142e-05  3.153348e-06  1.543514e-03  0.001033   \n",
       "1   5.583113e-03  4.345822e-04  7.502006e-06  2.364263e-02  0.001132   \n",
       "2   2.117221e-09  2.862016e-04  4.158496e-02  9.256034e-07  0.014289   \n",
       "3   1.818215e-15  2.585664e-07  4.931156e-02  2.472243e-10  0.027591   \n",
       "4   2.128355e-02  3.612888e-04  3.555209e-05  4.320706e-02  0.002542   \n",
       "5   5.857433e-05  6.009514e-03  1.837190e-06  1.467160e-04  0.000824   \n",
       "6   3.361572e-02  1.510170e-03  3.460343e-08  3.371302e-02  0.000184   \n",
       "7   1.213294e-03  1.456854e-04  1.554905e-03  5.186857e-03  0.007603   \n",
       "8   3.138494e-03  1.272224e-03  7.073253e-04  1.477244e-02  0.006385   \n",
       "9   3.996796e-05  7.475850e-03  6.999522e-03  2.149412e-04  0.015026   \n",
       "10  2.543299e-06  6.975654e-05  8.775717e-03  9.978224e-05  0.012134   \n",
       "11  6.430941e-10  8.092158e-06  2.736496e-02  2.786564e-07  0.017772   \n",
       "12  7.223292e-14  3.471981e-09  1.937811e-03  8.672912e-10  0.004243   \n",
       "13  2.680846e-02  8.270864e-03  1.724453e-08  2.398204e-02  0.000149   \n",
       "14  4.997448e-11  9.674188e-07  2.125577e-02  3.652677e-07  0.012963   \n",
       "15  2.137003e-03  1.972542e-02  1.712164e-05  1.276511e-02  0.003691   \n",
       "16  2.182393e-03  2.532663e-02  5.368031e-03  6.167508e-03  0.011716   \n",
       "17  1.117819e-03  1.116957e-05  7.894314e-08  1.246399e-02  0.000216   \n",
       "18  5.140298e-11  3.767794e-04  6.026766e-03  8.334968e-08  0.002145   \n",
       "19  7.967677e-04  8.758931e-03  1.229896e-02  3.055140e-03  0.009784   \n",
       "20  2.345667e-05  8.929261e-04  1.045647e-05  2.898557e-05  0.015012   \n",
       "21  2.616834e-04  7.161819e-04  9.239758e-03  2.383423e-03  0.014729   \n",
       "22  1.032817e-08  5.589440e-03  8.669947e-03  3.692293e-06  0.006042   \n",
       "23  5.180105e-05  1.039390e-01  1.161292e-04  1.975549e-04  0.003286   \n",
       "24  1.748035e-03  1.086584e-02  8.164150e-03  6.883197e-03  0.015710   \n",
       "25  5.876425e-02  3.984176e-02  2.206346e-10  1.617369e-02  0.000073   \n",
       "26  1.352434e-05  4.636052e-02  6.124565e-04  1.263843e-04  0.003284   \n",
       "27  5.748613e-12  3.126083e-05  9.744840e-04  2.292595e-08  0.000884   \n",
       "28  1.596730e-02  8.504610e-03  1.710547e-03  2.000252e-02  0.006100   \n",
       "29  9.508755e-03  3.138882e-03  6.213931e-04  2.181064e-02  0.005938   \n",
       "30  1.084821e-04  1.156065e-01  3.891247e-05  3.292833e-04  0.001992   \n",
       "31  2.329695e-02  1.011588e-02  2.844163e-07  6.146124e-03  0.002714   \n",
       "\n",
       "             119  \n",
       "0   8.141250e-07  \n",
       "1   5.605015e-06  \n",
       "2   2.847234e-02  \n",
       "3   1.039180e-01  \n",
       "4   9.242539e-05  \n",
       "5   5.982155e-06  \n",
       "6   2.827911e-07  \n",
       "7   3.409334e-03  \n",
       "8   3.944759e-04  \n",
       "9   1.122399e-02  \n",
       "10  1.218568e-02  \n",
       "11  4.310506e-02  \n",
       "12  2.055801e-03  \n",
       "13  8.777279e-08  \n",
       "14  1.685406e-02  \n",
       "15  3.717183e-05  \n",
       "16  7.172239e-03  \n",
       "17  8.519061e-08  \n",
       "18  1.356150e-03  \n",
       "19  9.727823e-03  \n",
       "20  4.284901e-03  \n",
       "21  9.128398e-03  \n",
       "22  4.959813e-03  \n",
       "23  4.601831e-04  \n",
       "24  9.414782e-03  \n",
       "25  3.826865e-08  \n",
       "26  7.322557e-04  \n",
       "27  1.418546e-04  \n",
       "28  2.113938e-03  \n",
       "29  7.138547e-04  \n",
       "30  1.472851e-04  \n",
       "31  8.235952e-05  \n",
       "\n",
       "[32 rows x 120 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model.predict(next(gen)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [names]\n",
       "Index: []"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(my_generator_tuple, model, class_names):\n",
    "    result = pd.DataFrame()\n",
    "    for element in my_generator_tuple:\n",
    "        predictions = model.predict(element[0])\n",
    "        names = element[1]\n",
    "        temp = pd.DataFrame({'idx': predictions.argmax(axis=1),\n",
    "                             'score': predictions.max(axis=1),\n",
    "                             'filenames': names})\n",
    "        temp['class_name'] = temp['idx'].apply(lambda x: class_names[x])\n",
    "        result = pd.concat([result,temp])\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_results(gen, model, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "#copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy result to folder\n",
    "def make_result_folder(df, class_names, test_path):\n",
    "        for element in class_names:\n",
    "            os.makedirs('/mnt/DataDisk/jodahr/data/Dogs/result/' + element, exist_ok=True)\n",
    "        for idx, row in df.iterrows():\n",
    "            dest = '/mnt/DataDisk/jodahr/data/Dogs/result/'\\\n",
    "                + row['class_name']\\\n",
    "                + '/' + str(row['score'])\\\n",
    "                + '_' + row['filenames']\n",
    "            src = test_path + '/' + row['filenames']\n",
    "            copyfile(src,dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_result_folder(df, class_names, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ce015d0d017c595bb64627a5749e3bd.jpg\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    print(row['filenames'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>idx</th>\n",
       "      <th>score</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>890f96dbc1f32ff2066a5572aaf78b9c.jpg</td>\n",
       "      <td>84</td>\n",
       "      <td>0.682099</td>\n",
       "      <td>papillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bf29aa547c53fe893b2c3547d58063cd.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>0.644949</td>\n",
       "      <td>entlebucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>f1b2c118e65c95ba1a00d102787d19a6.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>0.642773</td>\n",
       "      <td>beagle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d6519ebd4a475643e4c64043005cbb2.jpg</td>\n",
       "      <td>61</td>\n",
       "      <td>0.580584</td>\n",
       "      <td>japanese_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c636bf8d464b3601bf70681d1f1dd173.jpg</td>\n",
       "      <td>61</td>\n",
       "      <td>0.577773</td>\n",
       "      <td>japanese_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4423c704fafa60bf1df144f738340cef.jpg</td>\n",
       "      <td>86</td>\n",
       "      <td>0.567238</td>\n",
       "      <td>pembroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e073f14cd5f4c1a62cdb0108cca62fdd.jpg</td>\n",
       "      <td>61</td>\n",
       "      <td>0.567231</td>\n",
       "      <td>japanese_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13b4ff9966c0eb2586caff2225cac832.jpg</td>\n",
       "      <td>13</td>\n",
       "      <td>0.549237</td>\n",
       "      <td>blenheim_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d8e36262aac18be8c6ff387d097d8e2b.jpg</td>\n",
       "      <td>13</td>\n",
       "      <td>0.544927</td>\n",
       "      <td>blenheim_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5b54ee9719a556eb94c6ce232f6d78ff.jpg</td>\n",
       "      <td>13</td>\n",
       "      <td>0.537397</td>\n",
       "      <td>blenheim_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df69bb4b3dbdc81541e2bd70a5f35cb1.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>0.533821</td>\n",
       "      <td>entlebucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>66671fcc4ab3c92a34479bc1ac972458.jpg</td>\n",
       "      <td>107</td>\n",
       "      <td>0.532570</td>\n",
       "      <td>sussex_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6cdff5325cb35cfd44447b9e4f6cb7b4.jpg</td>\n",
       "      <td>61</td>\n",
       "      <td>0.527373</td>\n",
       "      <td>japanese_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>e9999f6b9a052810df4a5a762cb4cd1e.jpg</td>\n",
       "      <td>31</td>\n",
       "      <td>0.525016</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5f81e274485aa4ed061672e90cb69055.jpg</td>\n",
       "      <td>84</td>\n",
       "      <td>0.512411</td>\n",
       "      <td>papillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1820c9324897823981dc2e50bb155873.jpg</td>\n",
       "      <td>86</td>\n",
       "      <td>0.508852</td>\n",
       "      <td>pembroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b3f90b70c533cfaa5fdb35f646dfe89e.jpg</td>\n",
       "      <td>31</td>\n",
       "      <td>0.505842</td>\n",
       "      <td>clumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>978a013d5ce41091e621f1cccec64635.jpg</td>\n",
       "      <td>86</td>\n",
       "      <td>0.504008</td>\n",
       "      <td>pembroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fd0168c8b9fc33a5ba5a58c13d594bd0.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>0.503077</td>\n",
       "      <td>entlebucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a02a2f1ea51191fc24da9785456457dd.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>0.503077</td>\n",
       "      <td>entlebucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40cf82aac6661ef1210de377e22cf717.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>0.501652</td>\n",
       "      <td>entlebucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bbd6ebf6cea000cf5df2c649b138959d.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>0.483540</td>\n",
       "      <td>beagle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6d07e237578a419b0f317b2934e48584.jpg</td>\n",
       "      <td>107</td>\n",
       "      <td>0.480533</td>\n",
       "      <td>sussex_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc235032843333295c1e43551a715709.jpg</td>\n",
       "      <td>61</td>\n",
       "      <td>0.459960</td>\n",
       "      <td>japanese_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bfabbffb6f9f517741b4317bd6d9ef99.jpg</td>\n",
       "      <td>13</td>\n",
       "      <td>0.459879</td>\n",
       "      <td>blenheim_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>103cdc14a648474fa9a85c3542d6821e.jpg</td>\n",
       "      <td>84</td>\n",
       "      <td>0.443330</td>\n",
       "      <td>papillon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>f18141846c17b423f3f1df37ef294138.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>entlebucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f80081668f74c26b7084d8676ba12d9f.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>0.437174</td>\n",
       "      <td>beagle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>f89654f9652fed8140209b60093e6f3c.jpg</td>\n",
       "      <td>61</td>\n",
       "      <td>0.434359</td>\n",
       "      <td>japanese_spaniel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1f2e9080823a6b093e7a4baa668393d2.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>0.431643</td>\n",
       "      <td>entlebucher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35f79c19258eb98fb71d9f2c4444ec24.jpg</td>\n",
       "      <td>68</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df5e20faf083ef154fcd716dff396e1d.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.022211</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>667c969a3a1d19c86ca7e6ab2f877832.jpg</td>\n",
       "      <td>59</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>irish_wolfhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>65ada604355e106b920f5014701add9f.jpg</td>\n",
       "      <td>68</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8789588381a7f1b3970d974c9013637e.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90ad495de11baabadbd4aeb22b15b507.jpg</td>\n",
       "      <td>68</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ec7eab1c7a2275c89f2d3eca6e4afea2.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4a25bf2b77124daaddab4ec82810f31c.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>bernese_mountain_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>c18fc5b2ed455ba3857adc0d5830e837.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>e458d6133dd1b436b047f86910f7fe34.jpg</td>\n",
       "      <td>69</td>\n",
       "      <td>0.021798</td>\n",
       "      <td>leonberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cf14f9d5a0893a9fcefa7ddfca96311c.jpg</td>\n",
       "      <td>68</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>635c4c250784ebae26bf40f48a9a1e39.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.021762</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>944ec36bc768ee309e51bf881dabcb15.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>bernese_mountain_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b188a004aa9e0969567150d0d1f3c461.jpg</td>\n",
       "      <td>69</td>\n",
       "      <td>0.021678</td>\n",
       "      <td>leonberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a7c5c326cea8caee677f07df913fd570.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>0.021613</td>\n",
       "      <td>bernese_mountain_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79755a72f099c4823258d0387ae22f2e.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5e193ae2c366405e230a53daa4fb7721.jpg</td>\n",
       "      <td>52</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>great_pyrenees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17fac4b3bbf21f095de5564f9d18eec9.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>e9fe358382731f9288768526be01c950.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.021247</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>fe408b5f82c5de4133f5c105eb54388a.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.021227</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ad205d300e59f9ca7952805d9a192833.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d88cb9fa369a935b04c272faac0a4152.jpg</td>\n",
       "      <td>88</td>\n",
       "      <td>0.021042</td>\n",
       "      <td>pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13df0e8382cdcb5ed60c853079a3958e.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>0.020963</td>\n",
       "      <td>bernese_mountain_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a56375493c10603d38437d407e35c85d.jpg</td>\n",
       "      <td>68</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13d4e348df7d68efc1cc4da882c8485b.jpg</td>\n",
       "      <td>68</td>\n",
       "      <td>0.020894</td>\n",
       "      <td>lakeland_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>670a3370bb1ae920b7645508f969bc31.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>0.020787</td>\n",
       "      <td>samoyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>46d64fa64be77a9b6e5363ea3bdd72b8.jpg</td>\n",
       "      <td>59</td>\n",
       "      <td>0.020283</td>\n",
       "      <td>irish_wolfhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1ca48a6cbe0d436641764041dfe548ac.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>bernese_mountain_dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8bf8defe18c6db0efbd60d80706b1eab.jpg</td>\n",
       "      <td>59</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>irish_wolfhound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d87b71ae38bdaf656164cfe2c61bf7e8.jpg</td>\n",
       "      <td>36</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>dhole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10357 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filenames  idx     score            class_name\n",
       "20  890f96dbc1f32ff2066a5572aaf78b9c.jpg   84  0.682099              papillon\n",
       "24  bf29aa547c53fe893b2c3547d58063cd.jpg   42  0.644949           entlebucher\n",
       "26  f1b2c118e65c95ba1a00d102787d19a6.jpg    9  0.642773                beagle\n",
       "0   6d6519ebd4a475643e4c64043005cbb2.jpg   61  0.580584      japanese_spaniel\n",
       "19  c636bf8d464b3601bf70681d1f1dd173.jpg   61  0.577773      japanese_spaniel\n",
       "16  4423c704fafa60bf1df144f738340cef.jpg   86  0.567238              pembroke\n",
       "9   e073f14cd5f4c1a62cdb0108cca62fdd.jpg   61  0.567231      japanese_spaniel\n",
       "29  13b4ff9966c0eb2586caff2225cac832.jpg   13  0.549237      blenheim_spaniel\n",
       "2   d8e36262aac18be8c6ff387d097d8e2b.jpg   13  0.544927      blenheim_spaniel\n",
       "31  5b54ee9719a556eb94c6ce232f6d78ff.jpg   13  0.537397      blenheim_spaniel\n",
       "4   df69bb4b3dbdc81541e2bd70a5f35cb1.jpg   42  0.533821           entlebucher\n",
       "24  66671fcc4ab3c92a34479bc1ac972458.jpg  107  0.532570        sussex_spaniel\n",
       "7   6cdff5325cb35cfd44447b9e4f6cb7b4.jpg   61  0.527373      japanese_spaniel\n",
       "13  e9999f6b9a052810df4a5a762cb4cd1e.jpg   31  0.525016               clumber\n",
       "18  5f81e274485aa4ed061672e90cb69055.jpg   84  0.512411              papillon\n",
       "28  1820c9324897823981dc2e50bb155873.jpg   86  0.508852              pembroke\n",
       "20  b3f90b70c533cfaa5fdb35f646dfe89e.jpg   31  0.505842               clumber\n",
       "8   978a013d5ce41091e621f1cccec64635.jpg   86  0.504008              pembroke\n",
       "15  fd0168c8b9fc33a5ba5a58c13d594bd0.jpg   42  0.503077           entlebucher\n",
       "22  a02a2f1ea51191fc24da9785456457dd.jpg   42  0.503077           entlebucher\n",
       "8   40cf82aac6661ef1210de377e22cf717.jpg   42  0.501652           entlebucher\n",
       "13  bbd6ebf6cea000cf5df2c649b138959d.jpg    9  0.483540                beagle\n",
       "12  6d07e237578a419b0f317b2934e48584.jpg  107  0.480533        sussex_spaniel\n",
       "10  fc235032843333295c1e43551a715709.jpg   61  0.459960      japanese_spaniel\n",
       "31  bfabbffb6f9f517741b4317bd6d9ef99.jpg   13  0.459879      blenheim_spaniel\n",
       "13  103cdc14a648474fa9a85c3542d6821e.jpg   84  0.443330              papillon\n",
       "19  f18141846c17b423f3f1df37ef294138.jpg   42  0.438700           entlebucher\n",
       "2   f80081668f74c26b7084d8676ba12d9f.jpg    9  0.437174                beagle\n",
       "28  f89654f9652fed8140209b60093e6f3c.jpg   61  0.434359      japanese_spaniel\n",
       "7   1f2e9080823a6b093e7a4baa668393d2.jpg   42  0.431643           entlebucher\n",
       "..                                   ...  ...       ...                   ...\n",
       "18  35f79c19258eb98fb71d9f2c4444ec24.jpg   68  0.022244      lakeland_terrier\n",
       "0   df5e20faf083ef154fcd716dff396e1d.jpg   88  0.022211                   pug\n",
       "29  667c969a3a1d19c86ca7e6ab2f877832.jpg   59  0.022158       irish_wolfhound\n",
       "31  65ada604355e106b920f5014701add9f.jpg   68  0.022109      lakeland_terrier\n",
       "11  8789588381a7f1b3970d974c9013637e.jpg   88  0.022107                   pug\n",
       "17  90ad495de11baabadbd4aeb22b15b507.jpg   68  0.021984      lakeland_terrier\n",
       "13  ec7eab1c7a2275c89f2d3eca6e4afea2.jpg   88  0.021867                   pug\n",
       "30  4a25bf2b77124daaddab4ec82810f31c.jpg   11  0.021825  bernese_mountain_dog\n",
       "24  c18fc5b2ed455ba3857adc0d5830e837.jpg   88  0.021814                   pug\n",
       "23  e458d6133dd1b436b047f86910f7fe34.jpg   69  0.021798              leonberg\n",
       "4   cf14f9d5a0893a9fcefa7ddfca96311c.jpg   68  0.021764      lakeland_terrier\n",
       "18  635c4c250784ebae26bf40f48a9a1e39.jpg   88  0.021762                   pug\n",
       "14  944ec36bc768ee309e51bf881dabcb15.jpg   11  0.021679  bernese_mountain_dog\n",
       "17  b188a004aa9e0969567150d0d1f3c461.jpg   69  0.021678              leonberg\n",
       "23  a7c5c326cea8caee677f07df913fd570.jpg   11  0.021613  bernese_mountain_dog\n",
       "4   79755a72f099c4823258d0387ae22f2e.jpg   88  0.021600                   pug\n",
       "21  5e193ae2c366405e230a53daa4fb7721.jpg   52  0.021337        great_pyrenees\n",
       "23  17fac4b3bbf21f095de5564f9d18eec9.jpg   88  0.021272                   pug\n",
       "30  e9fe358382731f9288768526be01c950.jpg   88  0.021247                   pug\n",
       "30  fe408b5f82c5de4133f5c105eb54388a.jpg   88  0.021227                   pug\n",
       "16  ad205d300e59f9ca7952805d9a192833.jpg   88  0.021099                   pug\n",
       "9   d88cb9fa369a935b04c272faac0a4152.jpg   88  0.021042                   pug\n",
       "11  13df0e8382cdcb5ed60c853079a3958e.jpg   11  0.020963  bernese_mountain_dog\n",
       "11  a56375493c10603d38437d407e35c85d.jpg   68  0.020949      lakeland_terrier\n",
       "2   13d4e348df7d68efc1cc4da882c8485b.jpg   68  0.020894      lakeland_terrier\n",
       "19  670a3370bb1ae920b7645508f969bc31.jpg   94  0.020787               samoyed\n",
       "26  46d64fa64be77a9b6e5363ea3bdd72b8.jpg   59  0.020283       irish_wolfhound\n",
       "28  1ca48a6cbe0d436641764041dfe548ac.jpg   11  0.019828  bernese_mountain_dog\n",
       "31  8bf8defe18c6db0efbd60d80706b1eab.jpg   59  0.019623       irish_wolfhound\n",
       "7   d87b71ae38bdaf656164cfe2c61bf7e8.jpg   36  0.018178                 dhole\n",
       "\n",
       "[10357 rows x 4 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(predictions, class_names):\n",
    "       highest_score_index = predictions.argmax(axis=1)\n",
    "    highest_scores = predictions.max(axis=1)\n",
    "    class_name = [cls for cls in predictions]\n",
    "    return np.array([class_name, highest_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-baa3e11f41c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-215-91097cab5030>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(predictions, class_names)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhighest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#class_name = class_names[highest_score_index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighest_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'class_name' is not defined"
     ]
    }
   ],
   "source": [
    "decode(predictions, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97, 109,  52,  97, 109,  73,  31,  58,   9,  42,  54,  52,   2,\n",
       "        90,  90,  90,  86,  90,   7,  73,  12,  61,   7, 102,  75, 101,\n",
       "        87,  93, 101,  90,   1,  68])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = customGenerator(test_path,add_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = next(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bla[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla_test = test_path + '/' + bla[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 232.,  224.,  221.],\n",
       "        [ 216.,  194.,  173.],\n",
       "        [ 187.,  142.,  100.],\n",
       "        ..., \n",
       "        [  28.,   14.,    5.],\n",
       "        [  28.,   14.,    5.],\n",
       "        [  28.,   14.,    5.]],\n",
       "\n",
       "       [[ 216.,  209.,  203.],\n",
       "        [ 249.,  227.,  206.],\n",
       "        [ 185.,  140.,   98.],\n",
       "        ..., \n",
       "        [  28.,   14.,    5.],\n",
       "        [  28.,   14.,    5.],\n",
       "        [  28.,   14.,    5.]],\n",
       "\n",
       "       [[ 168.,  159.,  154.],\n",
       "        [ 255.,  250.,  229.],\n",
       "        [ 204.,  161.,  119.],\n",
       "        ..., \n",
       "        [  28.,   14.,    5.],\n",
       "        [  28.,   14.,    5.],\n",
       "        [  28.,   14.,    5.]],\n",
       "\n",
       "       ..., \n",
       "       [[ 112.,   70.,   22.],\n",
       "        [ 113.,   71.,   23.],\n",
       "        [ 116.,   74.,   26.],\n",
       "        ..., \n",
       "        [ 114.,   72.,   14.],\n",
       "        [ 113.,   71.,   13.],\n",
       "        [ 112.,   70.,   12.]],\n",
       "\n",
       "       [[ 114.,   72.,   24.],\n",
       "        [ 114.,   72.,   24.],\n",
       "        [ 116.,   74.,   26.],\n",
       "        ..., \n",
       "        [ 120.,   80.,   21.],\n",
       "        [ 119.,   79.,   20.],\n",
       "        [ 118.,   78.,   19.]],\n",
       "\n",
       "       [[ 130.,   88.,   40.],\n",
       "        [ 129.,   87.,   39.],\n",
       "        [ 127.,   85.,   37.],\n",
       "        ..., \n",
       "        [ 127.,   86.,   30.],\n",
       "        [ 125.,   84.,   28.],\n",
       "        [ 124.,   83.,   27.]]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_array(load_img(bla_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/DataDisk/jodahr/data/Dogs/test//2ce015d0d017c595bb64627a5749e3bd.jpg'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list_iterator' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0743161fe2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list_iterator' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/cpu:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15482518694837723954, name: \"/gpu:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 183631872\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 1626520279204157811\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:0c:00.0\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
